{
    "cc731a68-7dac-48db-a59b-e7c5f8d35e40": {
        "document_id": "cc731a68-7dac-48db-a59b-e7c5f8d35e40",
        "content": "A novel method for secure blockchain-based intellectual property protection using AI",
        "document_type": "patent",
        "owner": "John Doe",
        "created_at": "2025-02-26T15:13:05.887173",
        "metadata": {
            "keywords": [
                "blockchain",
                "IP protection",
                "AI"
            ],
            "status": "pending"
        },
        "hash": "3f6ea58a63a05c704f1dcb962d1f31a2c247f21733db8b592ebf1af538c7b204"
    },
    "d344fbdf-2925-4692-a46f-297a03d45bf1": {
        "document_id": "d344fbdf-2925-4692-a46f-297a03d45bf1",
        "content": "Memory SafetyWithoutRuntimeChecks or Garbage\nCollection\u2217\nDinakar Dhurjati Sumant Kowshik Vikram Adve Chris Lattner\nUniversityof Illinois at Urbana-Champaign\n{dhurjati,kowshik,vadve,lattner }@cs.uiuc.edu\nABSTRACT\nTraditional approaches to enforcing memory safety of pro-\ngrams rely heavily on runtime checks of memory accessesand on garbage collection, both of which are unattractive forembedded applications. The long-term goal of our work is\nto enable 100% static enforcement of memory safety for em-\nbedded programs through advanced compiler techniques andminimal semantic restrictions on programs. The key resultof this paper is a compiler technique that ensures memorysafety of dynamically allocated memory without program-\nmer annotations, runtime checks, or garbage collection ,a n d\nworks for a large subclass of type-safe C programs. Thetechnique is based on a fully automatic pool allocation (i.e.,region-inference) algorithm for C programs we developedpreviously, and it ensures safety of dynamically allocatedmemory while retaining explicit deallocation of individual\nobjects within regions (to avoid garbage collection). For a\ndiverse set of embedded C programs (and using a previoustechnique to avoid null pointer checks), we show that we areable to statically ensure the safety of pointer and dynamicmemory usage in all these programs . We also describe some\nimprovements over our previous work in static checking of\narray accesses. Overall, we achieve 100% static enforcement\nof memory safety without new language syntax for a signif-icant subclass of embedded C programs, and the subclass ismuch broader if array bounds checks are ignored.\nCategories and Subject Descriptors\nC.3 [ComputerSystemsOrganization ]: Special-Purpose\nand Application-based Systems; D.3 [ Software ]: Program-\nming Languages; D.4.6 [ Software ]: Operating Systems\u2014\nSecurity and Protection\nGeneral Terms\nSecurity, Languages\n\u2217This has been sponsored by the NSF Embedded Systems\nprogram under award CCR-02-09202 and in part by an NSFCAREER award, EIA-0093426 and ONR, N0004-02-0102.\nPermission to make digital or hard copies of all or part of this work for\npersonal or classroom use is granted without fee provided that copies are\nnot made or distributed for pro\ufb01t or commercial advantage and that copies\nbear this notice and the full citation on the \ufb01rst page. Tocopy otherwise, torepublish, topostonserversortoredistribute tolists,requires priorspeci\ufb01c\npermission and/or a fee.\nLCTES\u201903, June 11\u201313, 2003, San Diego, California, USA.\nCopyright 2003 ACM 1-58113-647-1/03/0006 ...\n$5.00.Keywords\nEmbedded systems, compilers, programming languages, static\nanalysis, security, region management, automatic pool allo-cation.\n1. INTRODUCTION\nCurrent and future embedded systems demand increas-\ning software \ufb02exibility, including the ability to upgrade orintroduce software modules into existing applications botho\ufb04ine and during active operation. Such software upgradesare becoming increasingly common for small consumer de-\nvices, and are expected to be important even for more con-\nstrained systems such as embedded control systems [23, 24]and sensor networks [20]. One of the key requirements forenabling dynamic software upgrades is to ensure that newsoftware modules or applications do not compromise the safeand correct functioning of an embedded device. One part\nof this problem is ensuring the memory safety of embedded\nsoftware, i.e., to guarantee that an upgraded software mod-ule cannot corrupt the code or data of its host application.(The term \u201cmemory safety\u201d is de\ufb01ned in Section 2.)\nUnfortunately, it appears that current language or system\napproaches for ensuring memory safety require signi\ufb01cant\noverheads in terms of runtime checks and garbage collec-\ntion. Safe languages like Java [10], Modula-3, ML, Safe-C [1], Cyclone [13] and CCured [22] use a variety of runtime\nchecks before individual memory operations such as bounds\nchecks for array references, null pointer references, and typeconversions, and they rely on garbage collection to ensure\nthe safety of references to dynamically allocated memory.\nThe overheads of runtime checking are quite signi\ufb01cant: lan-guages like SafeC, CCured, Cyclone and Vault have reportedslowdowns ranging from 20% up to 3x for di\ufb00erent applica-tions [1, 22, 11, 7].\nMany types of embedded software must operate under\nstringent energy, memory, and processing power limitations,and often under hard or soft real-time constraints as well.The runtime overheads of safety checks and both the over-heads and the potential unpredictability of garbage collec-tion are unattractive for such software [4].\nThe long-term goal of our work is to ensure memory safety\nfor embedded software while eliminating or greatly mini-mizing the need for runtime checks and garbage collection.Because this goal is impossible with ordinary language fea-tures such as arbitrary dynamic memory allocation, aliases,and array references, our strategy is to impose (minimal)\nsemantic restrictions on programs necessary to achieve this\n69 goal with existing compiler technology, and to reduce these\nrestrictions by developing new compiler techniques.\nIn previous work, we addressed the limited class of real-\ntime control applications (which typically use very simpledata structures and memory management) by designing arestricted subset of the C language appropriate for such pro-grams. This language, which we called Control-C, imposed\nonerous restrictions on dynamic memory allocation, pointer\nusage, and array usage [15]. We showed that with theserestrictions, existing compiler technology can permit 100%\nstatic checking of memory safety for this language. Unlikereal-time control codes, however, other kinds of embeddedapplications use dynamically allocated memory and arrays\nin much more complex ways, and the restrictions in Control-\nC would preclude writing such applications.\nA major technical challenge for broader classes of embed-\nded applications is allowing \ufb02exible dynamic memory allo-cation and deallocation without runtime checks or garbagecollection. Proving statically that a general C program (for\nexample) never dereferences a freed pointer (the \u201cdangling\npointer\u201d problem) is undecidable.\nSeveral recent languages including Real-time Java [4],\nCyclone [13], Vault [7], and others [26, 9, 5] have intro-duced language mechanisms for region-based memory man-agement. In this approach, the heap is partitioned into sep-\narate regions and deallocation is only permitted on an entire\nregion at once. These mechanisms guarantee the safety ofpointer-based accesses to region data without garbage col-lection, but have two key disadvantages:\n(1) Converting programs to use region-based mechanisms\ndemands signi\ufb01cant manual e\ufb00ort, typically requiringregion annotations on pointer variables, function in-terfaces, and allocation sites.\n(2) These region management schemes disallow explicit\ndeallocation of individual objects, so data structures\nthat must shrink and grow frequently (and have ob-\njects with non nested life times) have to fall back ona separate garbage-collected heap [4, 11] to avoid po-tentially unbounded growth in unused memory.\nAutomatic region inference algorithms have been devel-\noped that solve the \ufb01rst issue completely or partially, butonly for languages with no explicit deallocation such asML [25] and Cyclone [11] (i.e., languages which would oth-erwise require garbage collection).\nRecently, we developed a fully automatic region inference\nalgorithm called Automatic Pool Allocation that works cor-rectly for C programs with explicit malloc and free(in-\ncluding non-type-safe programs) [17]. The transformationsolves both the problems above because it is fully automatic\nand retains explicit deallocation of individual objects within\nregions. Each pool holds objects of a single size, thus elimi-nating fragmentation within pools and enabling very fast al-location and deallocation. Unfortunately, allowing individ-ual object deallocation means that the transformation doesnotensure memory safety (it makes no attempt to eliminate\nor restrict dangling pointers).\nThe main result of the current work is to extend Au-\ntomatic Pool Allocation to ensure memory safety withoutrequiring runtime checks, while retaining the performanceand memory bene\ufb01ts of the original algorithm (includingfully automatic region management without language anno-\ntations, and explicit deallocation of objects within regions).The key to our approach is that we do notprevent uses of\ndangling pointers to freed memory (e.g., a read, write, or\nfree on an already freed storage location); instead, we en-sure statically that such operations cannot cause violationsof type safety or memory safety.\nThe speci\ufb01c contributions of this paper are as follows:\n(a) We show how to use the Automatic Pool Allocation\ntransformation to ensure the safety of references todynamically allocated memory. We use an interpro-\ncedural \ufb02ow analysis of the compiler-generated pool\noperations to pinpoint data structures for which ourapproach could lead to increased memory consumptionby the program. The analysis also identi\ufb01es pools forwhich individual object deallocation can be completely\neliminated, without increasing memory consumption.\n(b) We extend our previous program restrictions and com-\npiler analysis for ensuring array access safety in order\nto support some common features that were disallowed\nbefore, including string manipulation, standard I/Ooperations, and argument vectors.\n(c) We evaluate how e\ufb00ective the new techniques in this\npaper (and other compiler safety checks retained fromthe previous work) are in permitting static checkingof memory safety, using a diverse collection of embed-ded programs from two widely used benchmark suites,\nMiBench [12] and MediaBench [19].\nOur experimental results show that we are able to stati-\ncally ensure the safety of pointer and dynamic memory us-agein all these programs . Our compiler analysis identi\ufb01es\nspeci\ufb01c data structures in two of these programs where our\nmemory management strategy could lead to some (probably\nsmall) potential increase in memory consumption. Overall,the approach promises safe dynamic memory managementwithout the overheads of runtime checks, and with negligiblemanual programmer e\ufb00ort. We believe that this is a majorstep towards achieving our long-term goal of 100% static\nenforcement of memory safety for embedded programs.\nOur results also show that two other essential techniques\ndeveloped in our previous work are adequate for the pro-grams studied here: a novel memory initialization strategyto eliminate runtime checks for null pointer references un-der a speci\ufb01c system assumption, and a compiler analysis for\nlifetimes of stack-allocated data. The former is su\ufb03cient for\nall our programs (and necessary for most), while the latterworks successfully for 16 out of 17 programs. Proving thesafety of array references, however, remains a major chal-lenge in achieving our long-term goal. With the extensions\nabove, we are able to prove the safety of array references in 8\nout of 17 of these programs. We draw some ideas for futurelanguage and compiler mechanisms that might succeed forthe other programs.\nThe rest of this paper is organized as follows. The next\nsection de\ufb01nes what we mean by memory safety and static\nchecking, brie\ufb02y describes our previous work on static safety\nchecking for real-time control systems, and summarizes theassumptions we make about programs and systems in ourcurrent work. Section 3 describes the language restrictionsand compiler techniques for ensuring safety of pointer ref-erences and heap management. Section 4 does the same\nfor array references. Section 5 describes our experiments\n70 evaluating the e\ufb00ectiveness of our techniques in supporting\ndi\ufb00erent classes of embedded applications. Section 6 com-\npares our work with previous work on providing programsafety through static techniques. Section 7 concludes witha summary of our results and suggests directions for furtherresearch.\n2. DEFINITIONS,PRIORWORK,ANDAS-\nSUMPTIONS\nFor the purposes of this work, we de\ufb01ne a software entity\n(a module, thread, or complete program) to be memory-\nsafeif (a) it never references a memory location outside the\naddress space allocated by or for that entity, and (b) it never\nexecutes instructions outside the code area created by thecompiler and linker within that address space. In practice,to enable static enforcement of the above requirements, wemust enforce stronger restrictions, e.g., strict type rules forall operations, limited type conversions, and in-bounds array\naccesses. The stronger restrictions also help to detect many\nkinds of errors at compile-time rather than at runtime.\nBy \u201cstatic enforcement\u201d or \u201cstatic checking\u201d of memory\nsafety, we mean that the compiler must ensure memorysafety without relying on garbage collection and without\nintroducing anyruntime checks before program operations\n(e.g., null pointer, array bounds, or type conversion checks).Some runtime support is still necessary, especially initializa-tion of global or dynamically allocated storage, and somesystem assumptions for error recovery described later.\nMany ordinary constructs in modern languages (particu-\nlarly array accesses and complex pointer-based data struc-\ntures) make it impossible to ensure memory safety via staticchecking alone. We therefore choose to impose some restric-tions on programs to make static checking possible. To makeit as simple as possible to modify existing embedded code toconform to our restrictions, we avoid adding anynew lan-\nguage mechanisms or syntax. Instead, we impose usage (i.e.,\nsemantic) restrictions that can be de\ufb01ned within the frame-work of an existing language, and checked by a compiler.\nAlthough our experiments focus on C programs in this\npaper, our semantic restrictions are de\ufb01ned in low-levellanguage-independent terms, and our safety checking com-\npiler is implemented entirely in a language-independent\ncompiler infrastructure called LLVM (Low Level VirtualMachine) [16]\n1. These features, together with the lack of any\nnew source-level constructs, imply that our safety-checkingstrategy can be used for programs in any source-level lan-\nguage compiled to LLVM object code.\n2.1 Control-C: MemorySafety forReal-Time\nControl Codes\nThe Control-C language de\ufb01ned in our previous work [15]\nimposed many semantic restrictions on C programs, andadded one new language mechanism for manual region al-location (described below). The goal was to enable 100%static checking of memory safety for real-time control codesusingexisting compiler techniques. We brie\ufb02y describe that\nlanguage to provide a basis for understanding how new com-\npiler techniques in the current work can eliminate the needfor some of these restrictions.\n1LLVM de\ufb01nes a simple, fully typed instruction set based on\nStatic Single Assignment (SSA) form as the input code rep-resentation in order to enable compile-time, link-time andruntime optimization of programs. See llvm.cs.uiuc.edu .There were 3 classes of restrictions in Control-C:\n\u007fType safety : Input programs had to be strongly typed.\nThese restrictions are retained in our current work.\n\u007fA\ufb03ne Expressions for Accessing Arrays : Control-C\nimposed restrictions on array index expressions andloop bounds so that the net e\ufb00ect is to produce an\na\ufb03ne relationship between the e\ufb00ective address ex-\npression and the size expression for each array dimen-sion. It also disallowed most common library func-tions and string operations. The a\ufb03ne requirement isretained in this work but a number of trusted library\nfunctions and string operations are now permitted.\n\u007fSingle-Region Dynamic Memory Allocation : Control-\nC imposed onerous restrictions on dynamic memory\nallocation and pointer usage, all of which have been\neliminated in the current work :\n\u2013Heap allocation was restricted to a single region\nat a time , and the entire region (i.e., all heap ob-\njects) had to be deallocated simultaneously.\n\u2013Every time the region was freed, all scalar point-\ners variables (local and global) had to be re-initialized before their next use.\n\u2013Structures or arrays containing pointers had to\nbe allocated dynamically, either on the heap oron the stack using C\u2019s alloca intrinsic.\nWe showed that these restrictions are adequate for many\nreal-time control algorithms, which tend to use very simpledata structures and memory management. They are clearly\ninadequate for broader classes of embedded programs. Elim-\ninating these restrictions and retaining static checking ofmemory safety requires new compiler techniques, particu-larly for array bounds checking and for heap and pointersafety. The current work primarily focuses on the latter,\nwhile making some simple improvements to the former.\n2.2 Assumptions of this Work\nThe system assumptions of the current work, plus the\nbasic language restrictions for type safety and pointer safetyare summarized below. The language restrictions for arraysafety are described in later sections.\nFirst, we make some assumptions about the runtime en-\nvironment. We assume that certain runtime errors are safe,i.e., the runtime system can recover from such errors bykilling the applet, thread, or process executing the untrustedcode. We assume a safe runtime error is generated if either\nthe stack or the heap grows beyond the available address\nspace. We assume the system has a reserved address range\nand any access to these addresses causes a safe runtime error,typically triggered by a page fault handler or by a reservedaddress range in hardware on systems without virtual mem-ory management.\n2If this is not available, some null pointer\nchecks must be inserted in the code, as described later.\nWe assume that certain standard library functions and\nsystem calls are trusted and can be safely invoked by theuntrusted code (calls whose arguments must be checked arediscussed in Section 4). We assume (and check) that the\n2For example, in standard Linux implementations, the high\nend of the process address space is reserved for the kernel,typically 1 GB out of 4 GB.\n71 source code of all other functions is available to the compiler.\nWe also require that the program be single-threaded.\nWe retain the basic type rules of Control-C, summarized\ninformally below. We assume a low-level type system in-cluding a set of primitive integer and \ufb02oating point types,arrays, pointers, user-de\ufb01ned records (structures), restrictedunion types, and functions.\n(T1) All variables, assignments, and expressions must be\nstrongly typed.\n(T2)C a s t stoa pointer type from any other type are disal-\nlowed. (Certain pointer-to-pointer casts for compati-\nble targets are considered safe, however.)\n(T3) A union can only contain types that can be cast to\neach other, e.g., a union cannot include a pointer and\na non-pointer type.\nEnforcing the above rules is trivial in LLVM [16], where all\noperations are typed and only an explicit castinstruction\ncan be used to perform any type conversion.\nWe also retain some rules required for ensuring pointer\nsafety, which are discussed in Section 3:\n(P1) Every local pointer variable must be initialized before\nbeing referenced, i.e., before being used or having its\naddress taken .\n(P2) Any individual data type (i.e., not an array) should be\nno larger than the size of the reserved address range.\n(P3) The address of a stack location cannot be stored in a\nheap-allocated object or a global variable, and cannotbe returned from a function.\n3. SAFETY OFPOINTER REFERENCES\nIn a language without garbage collection, and with the\ntype restrictions T 1\u2013T 3 above, there are three key ways\nin which pointer usage can lead to unsafe memory behavior:(a) Uninitialized pointer variables (either scalars or elements\nof aggregate objects) could be used to access invalid memory\naddresses. (b) A pointer into the stack frame of a functionthat is live after the function returns could be used to accessan object of a di\ufb00erent type (i.e., to violate type safety). (c)A pointer to a freed memory object (a \u201cdangling pointer\u201d)\ncould be used to access an object of a di\ufb00erent type allocated\nlater.\nThese three problems must be detected and disallowed at\ncompile-time or safely tolerated at runtime without intro-ducing checks for individual memory references. We exam-ine each of these conditions in turn in the following subsec-\ntions.\n3.1 Uninitialized pointers\nOur compiler prevents the \ufb01rst error above (due to unini-\ntialized pointer values) in the same way as in our previouswork, through a combination of static analysis and mini-\nmal runtime support [15]. We describe this brie\ufb02y here for\ncompleteness.\nFirst, we use a standard global data\ufb02ow analysis to\ncheck ruleP1above, which requires that all automatic\nscalar pointers must be initialized within their parent func-tion explicitly before they are dereferenced or their address\ntaken [15].Detecting uninitialized values for global variables and for\npointers within dynamically allocated data (e.g., structure\n\ufb01elds or arrays), is di\ufb03cult at compile-time. In order toavoid runtime null pointer checks, we initialize all uninitial-ized global scalar pointers and all pointer \ufb01elds in dynami-cally allocated data structures at allocation time to point tothe base of the reserved address range (analogous to the ini-\ntialization of \ufb01elds in Java). Pointer \ufb01elds in stack-allocated\nvariables of aggregate types are also initialized to the samevalue. Finally, the constant 0 used in any pointer-type ex-pression is replaced with the same value. Rule P2above\nspeci\ufb01es that the size of any individual structure type\n3can-\nnot exceed the size of the reserved address range. With this\nrule, the above initialization ensures that the e\ufb00ective ad-\ndress for the load of any scalar variable or structure \ufb01eldusing an uninitialized pointer will fall within the reservedaddress range, thus triggering a safe runtime error. If areserved address range is unavailable or the structure sizerestriction above is unacceptable, then runtime checks for\nnull pointer references would be required.\n3.2 Stack safety\nProblem (b) above potentially arises when the address of\na local variable (i.e., a pointer into the current stack frame)is made accessible after the function returns. To avoid thisproblem, many type-safe languages like Java disallow taking\nthe address of local variables. We choose to be less restric-\ntive: we only disallow placing the address of a stack locationin any heap location or global variable, or returning it di-rectly from a function (rule P3above).\nEnforcing this rule requires sophisticated compiler tech-\nnology, but no more than that required to perform Auto-\nmatic Pool Allocation for enforcing heap safety. In par-\nticular, we use Data Structure Analysis , a \ufb02ow-insensitive,\ncontext-sensitive (but very fast), interprocedural analysisthat computes a Data Structure Graph for each proce-\ndure [18]. This is a directed graph of all the memory objectsaccessible within a procedure, along with their types, their\nstorage class (stack, heap, global, formal parameter, return\nvalue, or local scalar temporaries), and the \u201cpoints-to\u201d linksbetween them. The graph for each function includes reach-able objects passed in from callers or returned from callees.\nRuleP3can now be enforced using a simple traversal\nof the Data Structure Graph for each function, checking\nwhether any stack-allocated object is reachable from thefunction\u2019s pointer arguments, return node or globals.\n3.3 Heap Safety\nThe third error above, that of detecting unsafe accesses\nto freed memory, is a particularly challenging problem for alanguage with explicit memory deallocation. The example\nin Figure 1 illustrates the challenges. Function fcalls g,\nwhich \ufb01rst creates a linked list of 10 nodes, initializes them,a n dt h e nc a l l s hto do some computation. gthen frees all\nof the nodes except the head and then returns. fthen uses\na dangling pointer reachable from the head. In such code,\nit is extremely hard for any compiler to statically identify\nwhich references (if any) may be unsafe and which are not.Moreover, consider h(), which allocates one node and frees\n3An array does not need this size restriction. An uninitial-\nized pointer used as an array reference will be caught by thearray bounds checker since the array will have no known sizeexpression.\n72 one node of the list 104times. Eliminating explicit frees\nby using region allocation (such as in Control-C, Cyclone,\nor other languages with nested regions) would increase theinstantaneous memory consumption of the program by 10\n4\n* sizeof(struct s) bytes because the region holding list\nitems can be freed only after exiting the function f.\nf() {\n...g(p);\n// p->next is dangling\np->next->val = ... ;\n}g(struct s *p) {\ncreate_10_Node_List(p);\ninitialize(p);h(p);free_all_but_head(p);\n}\nh(struct s *p) {\nfor (j=0; j < 100000; j++) {\ntmp = (struct s*) malloc(sizeof(struct s));insert_tmp_to_list(p,tmp);\nq = remove_least_useful_member(p);\nfree(q);\n}\n}\nFigure1: Pointersafetyandpoolallocationexample\nThe key principle underlying our approach is the follow-\ning:(Type homogeneity principle) If a freed memory block\nholdingasingleobjectweretobereallocatedtoanotherobjectof the same type and alignment, then dereferencing dangling\npointers to the previous freed object cannot cause a type vi-\nolation. This principle implies that to guarantee memory\nsafety, we do not need to prevent dangling pointers or theirusages in the source \u2013 we just need to ensure that theycannot be dereferenced in a type unsafe manner. The prin-ciple allows correct programs ( i.e.programs with no uses of\ndangling pointers), to work correctly without any runtime\noverhead. Programs with dangling pointer errors will exe-cute safely but we cannot (and do not need to) prevent sucherrors for these programs.\nUsing the above principle directly, one simple but imprac-\ntical solution is to separate the heap into disjoint pools for\ndistinct data types and never allow memory used for one\npool to be reused later for a di\ufb00erent pool. This is imprac-tical because it can lead to large increases in the instanta-neous memory consumption. The worst-case increase for aprogram with Npools would be roughly a factor of N\u22121,\nwhen a program \ufb01rst allocates data of type 1, frees all of it,\nthen allocates data of type 2, frees all of it, and so on.\nOur solution is essentially a more sophisticated applica-\ntion of this basic principle, using Automatic Pool Allocationto achieve type-homogeneous pools with much shorter life-times in order to avoid signi\ufb01cant memory increases as far\nas possible.\n3.3.1 Background: The Automatic Pool Allocation\nTransformation\nThe Automatic Pool Allocation transformation was de-\nveloped as a general compiler technique for enabling macro-\nscopic optimizations on logical data structures [17]. This\ntransformation introduces pool-based memory managementfor a subset of the disjoint data structures in an ordinary im-perative program that uses explicit allocation (e.g. malloc )\nand deallocation (e.g., free). It rewrites the allocation and\ndeallocation operations to use separate pools of memory for\neach logical data structure instance (e.g., a particular linkedlist or a graph) that is not exposed to unknown external\nfunctions. A pool is created before the \ufb01rst allocation for\nits data structure instance and destroyed at a point wherethere are no accessible references to data in the pool.\nWe use a pool allocation library with \ufb01ve simple op-\nerations: (a) poolinit(Pool** PP, TypeDesc* TD) cre-\nates a new pool for objects of the speci\ufb01ed type. (b)\npooldestroy(Pool* PP) destroys a pool and releases its re-\nmaining memory back to the system heap. (c) poolalloc\n(Pool* PP) and poolallocarray(Pool* PP, int N) allo-\ncate a single object or an array of Nobjects in the pool.\n(d)poolfree (Pool* PP, T* ptr) deallocates an object\nwithin the pool by marking its memory as available for real-\nlocation by poolalloc orpoolallocarray . The pool library\ninternally uses ordinary malloc andfreeto obtain memory\nfrom the system heap and return it when part of a poolbecomes unused or the pool is destroyed.\nThe pool allocation transformation operates as follows:\n1.Identify data structure (DS) instances : We traverse\nthe Data Structure Graph of each function (describedin Section 3.2) to identify maximal connected sub-graphs containing only heap nodes. Each such sub-graph represents a distinct heap-allocated data struc-ture.\n2.Identify where to create/destroy pools : For each pro-\ncedure, the DSG can be used to identify those data\nstructures that are not accessible after the procedure\nreturns (i.e., do not \u201cescape\u201d from the procedure to itscallers). For each such data structure, we insert callsto create and destroy pools of memory (one pool perdata type used in the data structure) at the entry andexit of the procedure.\n4In our running example, the\nlinked list does not escape from the procedure f()to\nits callers and so we create and destroy the pool forthe list in procedure f(), as shown in Figure 2.\n3.Transform (de)allocation operations and function in-\nterfaces : We transform all malloc and freecalls in\nthe original program to use the pool allocation ver-sions, as illustrated in function h(). For any function\ncontaining such operations on a pool created outside\nthe function, we add extra arguments to pass the ap-\npropriate pool pointers into the function (and do thesame for possible callers of such functions, and theircallers and so on).\n5This is illustrated by the functions\ng()and h()and their invocations in Figure 2.\nThe result of this transformation for type-safe programs\nis that all heap-allocated objects are assigned to type-homogeneous pools, disjoint data structure instances (asde\ufb01ned above) are assigned to distinct sets of pools, andindividual items are allocated and freed from the individ-ual pools at the same points that they were before. A pool\nis destroyed when there are no more live (i.e., reachable)\nreferences to the data in the pool.\n4Our pools do not require nested lifetimes. We could move\npoolinit later in the function and move the pooldestroy\nearlier or into a callee using additional \ufb02ow analysis, but wedo not do so currently.\n5Data Structure Analysis also identi\ufb01es the targets of func-\ntion pointers and constructs a call graph, allowing us tohandle programs with indirect calls and recursion.\n73 f() {\nPool *PP;poolinit(PP, struct s);...\ng(p, PP);\n// p->next is danglingp->next->val = ... ;\npooldestroy(PP);\n}g(struct s *p, Pool *PP) {\ncreate_10_Node_List(p, PP);\ninitialize(p);h(p, PP);\nfree_all_but_head(p, PP);\n}\nh(struct s *p, Pool *PP ) {\nfor (j=0; j < 100000; j++) {\ntmp = poolalloc(PP);\ninsert_tmp_to_list(p, tmp);q = remove_least_useful_member(p);\npoolfree(PP, q);\n}\n}\nFigure2: Exampleafterpoolallocationtransforma-\ntion\nNote that the transformation as described so far does not\nensure program safety . Explicit deallocation via ( poolfree )\ncan return freed memory to its pool and then back to thesystem, which can then allocate it to a di\ufb00erent pool. Dan-gling pointers to the freed memory could violate type safety.\n3.3.2 Exploiting PoolAllocationforHeapSafety\nThe basic principle of type homogeneity mentioned ear-\nlier can be applied to ensure program safety after the pool\nallocation transformation. Since our pools are already type-homogeneous, we simply need to ensure that the memorywithin some pool P\n1is not used for any other dynamically\nallocated data (either another pool P2or heap allocations\nwithin trusted libraries) until P1is destroyed. This can be\ndone easily by modifying the runtime library so that mem-\nory of a pool is not released to the system heap except bypooldestroy . This change can have the same disadvantage\nas the na \u00a8ive type-based pools \u2013 the memory requirement of\nthe program could increase signi\ufb01cantly.\nNote, however, that our pools are much more short-lived\nthan in the na \u00a8ive approach and are tied to dynamic data\nstructure instances in the program, not static types. Weexpect, therefore, that during the lifetime of a pool, themost important reuse of memory (if any) is within the pool\nrather than between the pool and other pools. Only thelatter causes any potential increase in memory consumption.\nNevertheless, any such increases are likely to be of signi\ufb01cant\nconcern to programmers of embedded systems.\nThe goal of our further analysis is to distinguish the sit-\nuations outlined above, and inform the programmer aboutdata allocation points where potential memory increases can\noccur. We can classify each pool Pinto three categories:\nCase 1 (No reuse): Between any poolfree for pool P\nand the pooldestroy for P, there are no calls to poolalloc\nfrom any pool including Pitself. In this case, there is no\nreuse of P\u2019s memory until Pis destroyed. Figure 3(a) illus-\ntrates this situation. Note that all poolfree calls to Pcan\nbeeliminated as a performance optimization . This is essen-\ntially static garbage collection for the pool since its memoryis reclaimed by the pooldestroy introduced by the compiler.\nCase 2 (Self-reuse): Between any poolfree operation\non pool Pand the call to pooldestroy for P,t h eo n l y\npoolalloc operations are to the same pool P.I nt h i sc a s e ,the only reuse of memory is within pool P, and the explicit\ndeallocation via poolfree ensures that no increase in the\nprogram\u2019s memory consumption will occur. This is illus-trated in Figure 3(b): after the \ufb01rst poolfree onp1there\nare new allocations in pool p1(via the function addItems ),\nbut not by any other pool.\nCase 3 (Cross-reuse): Between the \ufb01rst poolfree op-\neration on Pand the pooldestroy for pool P.t h e r e a r e\npoolalloc operations for other pools. Pool p1i nF i g u r e3 (c )\nfalls in this category because there are allocations from poolp2via the call to addItems(p2,t) . Our transformation in this\ncase may lead to increased memory consumption, and we re-q u i r et h i st ob ea p p r o v e db yt h ep r o g r a m m e rv i aac o m p i l e r\noption. In such situations, a programmer should be able\nto estimate the potential memory increase through manualanalysis or pro\ufb01ling. In practice, we expect the amount ofmemory released by one pool and used by another, beforethe \ufb01rst pool is destroyed, will be relatively small.\nNote that the pool in our running example of Figure 2 has\nonly self-reuse, and we can guarantee memory safety without\nany increase in memory consumption. Our experiments inSection 5 have produced very few instances of case 3, andin only 2 out of the 17 embedded codes we examined.\n3.3.3 CompilerImplementation\nThe compiler \ufb01rst applies the type checking, stack safety,\nand array safety analyses to the original program. It then\napplies Automatic Pool Allocation to transform the program\nas described earlier. We have modi\ufb01ed our runtime pool al-location library so it does not release free memory in a poolback to the system heap until the pool is destroyed. Thekey goal of the new compiler analysis is to identify situa-tions where this can lead to a potential increase in memory\nconsumption by categorizing pools as described above.\nCategorizing pools requires analyzing the potential order\nof execution of pool operations a c r o s st h ee n t i r ep r o g r a m ,\nusing an interprocedural control \ufb02ow analysis. AutomaticPool Allocation records information about the pools usedin each function and the locations of calls to poolalloc ,\npoolfree and pooldestroy inserted for each pool. Pool\npointers are passed between procedures but they are nototherwise copied and their address is never taken, so eachpool pointer variable within a function identi\ufb01es a uniquepool. Our current pool allocation transformation places thecalls to pooldestroy at the end of the function containing\nthe call to poolinit for that pool.\n6\nThe algorithm for identifying and categorizing reuse within\nand across pools is shown in Figure 4. We say a func-tion F(or a call site C) indirectly calls a pool operation\n(e.g., poolfree ) if it calls some function that may directly\nor indirectly call that operation. The sets FreeSites(F,P)\nand AllocSites(F,P) respectively identify the call sites\nwithin function Fthat directly or indirectly invoke poolfree\nand poolalloc on pool P.T h es e t s PoolsFreed(F) and\nPoolsAlloced(F) respectively are sets of incoming pools\n(i.e., formal pool pointer arguments to function F)f o rw h i c h\nFmay directly or indirectly call poolfree orpoolalloc .\nConsider \ufb01rst a single-procedure program containing calls\ntopoolfree ,poolalloc and pooldestroy . The analysis\nthen traverses paths from a poolfree for a pool to the\n6The algorithms described in this section can be easily modi-\n\ufb01ed if poolinit andpooldestroy calls are placed di\ufb00erently\nby Pool Allocation.\n74 p1 = poolinit(s);\nt = makeTree(p1);while(...) {\nprocessTree(p1,t);\nfreeSomeItems(p1,t);\n}\nfreeTree(p1,t);poolDestroy(p1);p1 = poolinit(s);\nt = makeTree(p1);while(...) {\nprocessTree(p1,t);\nfreeSomeItems(p1,t);\naddItems(p1,t); // self-reuse\n}\nfreeTree(p1,t);poolDestroy(p1);p1 = poolinit(s);\nt = makeTree(p1);while(...) {\nprocessTree(p1,t);\nfreeItems(p1,t);\naddItems(p1,t); // self-reuseaddItems(p2,t); // cross-reuse\n}\nfreeTree(p1,t);poolDestroy(p1);\n(a)Noreuse (case 1) (b)Self-reuse (case 2) (c)Self-andCross-reuse (case 3)\nFigure 3: Exampleillustrating3 typesof reuse behaviorfor a pool p1.\nunique pooldestroy of that pool, looking for all calls to\npoolalloc that appear on such a path. This is shown as\nroutine AnalyzeFunction in Figure 4. (It is easy to handle\nall pools in a single linear-time traversal of the Control FlowGraph, but the version in the \ufb01gure is much easier to un-derstand.) Each pool is then categorized according to whatinstances of poolalloc , if any, are found on such paths.\nConsider next an input program without recursion. The\nalgorithm then makes a bottom-up traversal of the callgraph, computing the four kinds of sets above for eachfunction. The bottom-up traversal ensures that the setsPoolsFreed(C) and PoolsAlloced(C) will be computed for\nall possible callees Cof a function F, before visiting F.\nTo compute the sets for F, we visit each call site SinF\nand add this call to FreeSites(F,P) if it causes an invo-\ncation of poolfree(P) ,a n dt o AllocSites(F,P) similarly.\nWe also add each pool so encountered to PoolsFreed(F) or\nPoolsAlloced(F) . We can now invoke AnalyzeFunction(F)\ndirectly to classify all pools in F.N o t et h a t AnalyzeFunction(F)\nmakes no distinction between local and indirect calls to\npoolfree /poolalloc for pool Psince both kinds of call sites\nare included in FreeSites(F,P) and AllocSites(F,P) .\nTo handle recursive and non-recursive programs uni-\nformly, we actually perform the bottom-up traversal on theStrongly Connected Components (SCC\u2019s) of the call graph.\nWithin each SCC, we use a simple iterative algorithm in\nwhich the sets are propagated from a function to its callsiteswithin the SCC until the sets FreeSites(F,P) and\nAllocSites(F,P) stabilize for all functions Fin the SCC\nand every pool P. Once they have stabilized, the sets can be\npropagated from each function in the SCC to every call site\nof that function outside the SCC. AnalyzeFunction is then\napplied to each function Fin the current SCC as explained\nearlier.\n4. ARRAYRESTRICTIONS\nIn general, array bounds checking in general programs is\nundecidable. In our previous work [15], we designed lan-guage restrictions on array usage (rules (A1\u2013A3) in Fig. 5)that enable complete symbolic checking of array accesses.RestrictionA3says that every index expression in an array\nreference must have a provably a\ufb03ne relationship to the al-\nlocated array size for that dimension. We also described an\ninterprocedural constraint propagation algorithm that prop-agates a\ufb03ne constraints on integer variables from callers tocallees (for incoming integer arguments and global scalars)and from callees to callers (for integer return values andglobal scalars), as described in [15]. We can then perform a\nsymbolic bounds check for each index expression using in-teger programming (our compiler uses the Omega Library\nfrom Maryland [14]).\nFor array safety, our primary goal in this work has been\nto evaluate the adequacy of these rules for a broad range ofembedded programs, and to relax the rules in limited waysthat can still be checked with existing compiler and integerprogramming technology. We have found (not surprisingly)\nthat embedded codes typically use arrays in much more com-\nplex ways than the control codes studied in our previouswork, as our experimental results in Section 5 show.\nOne practical issue for embedded programs is that they\nmake signi\ufb01cant use of I/O operations, the string library,and command line arguments. We added rule (A4)in Fig. 5\nto allow certain trusted string and I/O library routines.\nThe rule also speci\ufb01es that the arguments to trusted libraryroutines must satisfy some safety preconditions, to preventbu\ufb00er overruns within the library routines. Some libraryroutines also provide constraints relating the output of theroutine to its inputs which must be used by the compiler to\ncheck bu\ufb00er or string safety. For example, the expression n\n= read(fd, buf, count) where bufis a character array has\nthe safety precondition, (buf.size >= count) and a con-\nstraint on the return value, (n <= count) since readcan\nonly read up to countbytes. Some trusted library calls and\nthe corresponding constraints are listed in Table 1.\nLibrary Call\n Return Value\n Safety Pre-\nConstraints\n conditions\nn = read(fd, buf,\n n <= count\n buf.size\ncount)\n >= count\nn = puts(s)\n -\n -\np = memcpy(p1, p2,\n p.size = p1.size\n p1.size\nn)\n >= p2.size\nfp = fopen(p,m)\n -\n -\nn = getc(s)\n -\n -\nn = strlen(s)\n n < s.size\n -\np = strcpy(s1,s2)\n p.size = s1.size\n s1.size\n>= s2.size\np = strdup(s)\n p.size = s.size\n -\np = strncpy(s1, s2,\n p.size = s1.size\n s1.size > n\nn)\nTable 1: Some Trusted Library Routines with Im-pliedConstraintsand Preconditions\nThe advantage of providing trusted routines with pre-\nde\ufb01ned constraints (rather than including their source codein our analysis) is two-fold. It allows the body of the li-\nbrary routine to use non-a\ufb03ne array accesses or non-type-\n75 FreeSites(F,P) : set of call sites in F that may call poolfree on pool P directly or indirectly\nAllocSites(F,P): set of call sites in F that may call poolalloc on pool P directly or indirectlyPoolsFreed(F) : set of pool arguments of F that may have a poolfree in F or one of its calleesPoolsAlloced(F): set of pool arguments of F that may have a poolalloc in F or one of its callees\nAnalyzeFunction(Function F)\nbegin\nfor (each pool pointer SSA variable P in F) // formal argument or local variable\nfor (each call site FI in FreeSites(F, P))\nfor (each call AI in AllocSites(F, P1) where P1 != P)\nif (there exists a path from FI to AI in the Control Flow Graph)\nClassify (F,P) as \u2018\u2018Case 3\u2019\u2019\nfor (each call AI in AllocSites(F, P))\nif (there exists a path from FI to AI in the Control Flow Graph)\nClassify (F,P) as \u2018\u2018Case 2\u2019\u2019\nif !(Case 2 OR Case 3)\nClassify (F,P) as \u2018\u2018Case 1\u2019\u2019\nend;\nAnalyzeProgram(Program M)\nbegin\nfor (each SCC in CallGraph of M in post-order)\nwhile (change == true)\nchange = falsefor (each function F in the SCC)\nfor (each pool pointer variable P in F) // formal argument or local variable\nfor (each call site CS in F that has P as an argument)\nfor (each function CalledF that can be called at CS)\nif (CalledF is poolfree for P OR PoolsFreed(CalledF) contains P)\nif (FreeSites(F,P) does not contain CS)\nchange = trueadd CS to FreeSites(F,P)\nif (P is an argument of F)\nadd P to PoolsFreed(F)\nif (CalledF is poolalloc on P OR PoolsAlloced(CalledF) contains P)\nif (AllocSites(F, P) does not contain CS)\nchange = true\nadd CS to AllocSites(F,P)if (P is an argument of F)\nadd P to PoolsAlloced(F)\nfor (each function F in the SCC)\nAnalyzeFunction(F)\nend;\nFigure 4: Algorithmto identifyand classifypotential memoryreuse withinand betweenpools\nsafe code. Also, we do not need to compute or propagate\ndetailed constraints from the body of the library routine,thus speeding up the analysis.\nFinally, to ensure that string routines will not read beyond\nthe size of the array, we always initialize the last character\nin any array of characters to be null. We added rule (A5)to\nrequire that the program must not modify the last character,and enforce this rule by excluding the last element in thearray size expression used for safety checking.\nThe pre-conditions and return-value constraints are di-\nrectly incorporated into our existing analysis for arraybounds, described in [15]. We explain the basics of our ap-proach with the help of the example in Figure 6.\nTo prove the safety of any array access we \ufb01rst collect\nconstraints from the index expression and the array size ex-\npression by following SSA def-use edges, and collect branch\nconditions on which those de\ufb01nitions depend by using thecontrol dependence graph. In our example, for array ac-cess A[i], the constraints we generate are (A.size = 51-1)\nusing the def-use edges from the array declaration (notethat the last character is excluded from the size), (lenchar A[51]; // last character is set to null\n...k = read(fd, A, 50); // requires A.size >= 50\nif (k > 0) {\nlen = strlen(A); // implies len < A.sizefor (i=0; i < len; i++)\nif (A[i] == \u2019-\u2019)\nbreak;\n... // do other stuff with A, i\n}\nFigure 6: Array Usage Example\n< A.size && k <= 50) using the def-use edges and return\nvalue constraints on library functions strlen andread,a n d\n(i < len && k > 0) from the control dependence graph.\nInduction variable recognition allows us to generate usefulconstraints about loop index variables (e.g., i> =0 ), and\n(together with the renaming of variables in SSA form) al-lows us to disregard inconsistent equations like i=i+1\nfor both induction variables and ordinary variables. The\n76 Onallcontrol\ufb02owpaths,\n(A1) Theindexexpressionusedinanarrayaccessmustevaluatetoavaluewithintheboundsofthearray.\n(A2) Foralldynamicallyallocatedarrays,thesizeofthearraymustbeapositiveexpression.\n(A3) Ifanarray, A,isaccessedinsidealoop,then\n(a) theboundsoftheloopmustbeprovablya\ufb03netransformationsofthesizeof Aandouterloopindexvariablesorviceversa;\n(b) theindexexpressioninthearrayreference,mustbeaprovablya\ufb03netransformationofthevectorofloopindexvariables,or\nana\ufb03netransformationofthesizeof A;and\n(c) iftheindexexpressioninthearrayreferencedependsonasymbolicvariable swhichisindependentoftheloopindexvariable\n(i.e.,appearsintheconstantterminthea\ufb03nerepresentation),thenthememorylocationsaccessedbythatreferencehavetobeprovably independentofthevalueof s.\n(A4) Asetoftrustedlibraryroutineswithspeci\ufb01edpreconditionsmaybeused,andargumentspassedtothoseroutinesmustsatisfy\nthepreconditions.\n(A5) Thelastelementofacharacterarraycannotbemodi\ufb01edbytheprogram.\nFigure 5: SemanticRestrictions on Array Usage\ncomplete set of constraints that we generate for this ac-\ncess are (A.size = 50 && len < A.size && k <= 50 && i\n< len && k > 0 && i >= 0) . (Note that the interprocedu-\nral constraint propagation is not necessary in this simple\nexample but is essential for most realistic applications inpractice.) Finally, we add the illegal array bounds condi-tions for the reference ( (i < 0 || i >= A.size) in the ex-\nample), and then use the Omega library [14] to check if theresulting constraint system is satis\ufb01able. If not (as we have\nhere), the constraints have been proven inconsistent and the\narray access is safe.\nTo verify the precondition for the trusted library call read,\nwe simply need to check if the negation of the precondition(A.size >= 50) along with known constraints on buf.size\nand countresults in an inconsistent system. Here, (A.size\n< 50 && A.size = 50) trivially results in an inconsistent\nsystem. In this manner, we generate and check the precon-ditions for every trusted library call used by the program.\n5. RESULTS\nIn this section, we address some of the key questions about\nthe e\ufb00ectiveness of our semantic restrictions and compilertechniques used to check memory safety:\n1. How much e\ufb00ort is required to convert the existing\nembedded programs to conform to our semantic re-strictions ?\n2. Are the pool allocation transformation and heap safety\nanalysis powerful enough to enforce pointer and heapsafety statically in di\ufb00erent embedded programs?\n3. How often do we encounter pools from each of the three\ncategories in these programs?\n4. Are the array restrictions \ufb02exible enough to permit\nexisting embedded codes (without extensive changes)?\n5. Are the semantic restrictions and static analyses for\nstack safety su\ufb03cient for existing embedded codes?\n5.1 Methodology and Porting Effort\nOur test codes were derived from two embedded applica-\ntion benchmark suites: 13 from MiBench [12] and 4 fromMediaBench [19].\n7MiBench consists of embedded codes\n7Other codes in the benchmarks are not accepted by the\ncurrent LLVM C front-end, but will be evaluated using anew version of the front-end in the near future.from a variety of domains including telecommunications,\nsecurity, networking, etc. MediaBench are predominantlymultimedia codes. The program rastause a library called\nlibsphere whose source was not available. The experiments\nforrastaassumed that this library is safe and checked the\nsafety of the available source. The benchmarks, their sizes,and our results for each are shown in Table 2.\nWe found that a few lines of code had to be changed in\nseveral benchmarks to conform to our rules, particularly for\ntype safety and array safety. These are shown in the third\nand fourth columns of Table 2. The two largest changes werefor rule(T3)inrastaandg721.rastaused a union with a\n\ufb02oat and an array of four chars to swap the bytes of the \ufb02oatvalue. g721did the same for an unsigned int. We rewrote\nthe code using shift operations and eliminated the union.\nThe other changes for type safety were very small, e.g., ini-\ntializing local pointer variables before use within their par-ent function. For the array safety rules, we had to rewrite afew lines of code in 8 programs. The changes were generallyminimal and obvious. For instance, in blowfish a command\nline argument was accessed by iterating and checking if the\nlast character was null, which had to be rewritten to usestrlen() for the loop bound.\nBesides requiring very few modi\ufb01cations, the changes\nthemselves were simple and local and in most cases obvi-ous from reading the code or from compiler error messages.\nOverall, we believe the porting e\ufb00ort to use our compiler for\nstandard C programs is small to negligible.\n5.2 Effectiveness of Pointer and Heap Safety\nAnalysis\nTheHeap and Pointer Safety column in Table 2 shows\nthat our compiler was able to enforce safety of heap and\npointer usage for all 17 benchmarks we studied. About half\nthe benchmarks use no dynamic memory allocation (thoughthey still use pointers). For the other benchmarks, the samecolumn shows the di\ufb00erent categories of pools found in eachone. The results show that we were able to prove heap\nsafety without increase in memory consumption (i.e., Case\n1 or Case 2 pools \u2014 no reuse or only self-reuse), for all 13MiBench benchmarks and 2 of the 4 MediaBench codes.\nOnly two codes, rasta and epic, have pools with cross-\nreuse by other pools (Case 3), which can incur some increasein memory consumption. We believe this is an encouraging\nresult. Both rastaandepicmake extensive use of dynamic\n77 Benchmark\n Lines of\n Lines of Code\n Lines of Code\n Array Bounds\n Heap and\n Stack Safety\nCode\n Modi\ufb01ed\n Modi\ufb01ed\n Checker\n Pointer Safety\nfor type safety\n for array safety\n (Case)\nautomotive\nbasicmath\n 579\n 1\n 3\n Yes\n Yes\n Yes\nbitcount\n 17\n 5\n 0\n Yes\n Yes\n Yes\nqsort\n 156\n 0\n 1\n Yes\n Yes\n Yes\nsusan\n 2122\n 1\n 0\n No\n Yes (Case 1)\n Yes\no\ufb03ce\nstringsearch\n 3215\n 0\n 3\n Yes\n Yes\n Yes\nsecurity\nsha\n 269\n 0\n 1\n Yes\n Yes\n Yes\nblow\ufb01sh\n 1502\n 1\n 5\n Yes\n Yes\n Yes\nrijndael\n 1773\n 3\n 6\n Yes\n Yes\n No\nnetwork\ndijkstra\n 348\n 0\n 0\n No\n Yes (Case 2)\n Yes\ntelecomm\nCRC 32\n 282\n 0\n 1\n Yes\n Yes\n Yes\nadpcm codes\n 741\n 0\n 0\n No\n Yes\n Yes\nFFT\n 469\n 0\n 0\n No\n Yes (Case 1)\n Yes\ngsm\n 6038\n 0\n 0\n No\n Yes (Case 1)\n Yes\nmultimedia\ng721\n 1622\n 11\n 0\n No\n Yes\n Yes\nmpeg(decode)\n 9839\n 0\n 0\n No\n Yes (Case 1)\n Yes\nepic\n 3524\n 4\n 0\n No\n Yes (Cases 1,3)\n Yes\nrasta\n 7373\n 13\n 0\n No\n Yes (Cases 1,3)\n Yes\nTotals: 17\n 39869\n 39\n 20\n 8\n 17\n 16\nTable2: Benchmarks,code sizes,and experimentalresults\nmemory, yet they contain very few pools that fall under Case\n3: just 1 such pool out of a total of 13 pools in epicand 5\nout of 14 in rasta.I nf a c t ,3o ft h o s e5p o o l si n rastaalso\nhave self-reuse from the same pool, so that the e\ufb00ect of notfreeing memory to other pools is mitigated. We have alsoobserved that some case 3 pools (such as the one in epic)\ncould be converted to case 1 or 2 with more sophisticated\ncompiler analyses where the pooldestroy on a pool is moved\nas close to the last poolfree on the pool as possible without\ncompromising safety.\nAnother interesting use of dynamic memory is seen in\ndijkstra , where a linked list is alive throughout the pro-\ngram and repeatedly allocates and deallocates memory. In\na language with explicit regions such as Cyclone [11] or RT-\nJava, this list would have to go on a garbage collected heap.Finally, there were a number of Case 1 pools, which areamenable to the optimization of turning o\ufb00 individual objectfrees entirely, e\ufb00ectively performing static garbage collection\nwith no increase in memory usage.\nOverall, our results indicate that Case 3 occurs infre-\nquently even in complex embedded codes and typically neveroccurs at all in the simpler codes. This is strong empiricalevidence that our technique is powerful enough to enforceheap safety statically in a broad range of embedded codes.\n5.3 Effectiveness of Stack Safety Checks\nOur stack safety check ensures that pointers to the stack\nframe in a function are not accessible after that functionreturns. The last column of Table 2 shows that only 1 pro-gram ( rijndael ) failed this check. This occurred because\nData Structure Analysis is \ufb02ow-insensitive and can yeildfalse positives. In rijndael , a pointer to a local variable\nis stored in a global but the global is reinitialized by a calleeof the function before the function returns. Such cases must\nbe handled by restructuring the program. Overall, these re-\nsults indicate that stack safety should not be a signi\ufb01cantobstacle for static safety checking with our approach.\n5.4 Effectiveness of Array Access Checks\nOur array bounds checker passed 8 of the 13 benchmarks\nfrom MiBench and none from MediaBench, after the fewchanges described earlier. Interestingly, our tests detected 3\npotential array bound violations in the MiBench suite and\n2 in MediaBench: one each in dijkstra (both the large and\nsmall versions) and blowfish and two violations in g721.A l l\nof the errors except the ones in g721 were due to incorrectassumptions on number of command line arguments. Theerror in g721 was in using a \ufb01xed size bu\ufb00er to copy a \ufb01le\nname obtained from a command line argument. This could\ncause a stack corruption.\nThe array bounds checking algorithm failed to prove\nsafety for 9 of the codes. Two of these codes used non-a\ufb03nebit operations on the index variables. 5 other codes use indi-\nrect indexing for arrays, e.g., A[B[j]]. One possible solution\nwe aim to explore is to use Ada style subrange types forindex expressions, and attempt to prove their safety whenthe index values are computed .\nAnother two codes use memory locations in the heap to\nstore the size of an array, then load and use this size value\nin another function, requiring the compiler to prove that the\nheap location is not modi\ufb01ed in between. We believe thatthis can be handled fairly simply by interprocedural loadvalue numbering.\nOverall, safety checking of complex array references re-\nmains the most signi\ufb01cant obstacle to our goal of 100% static\nsafety checking for a broad class of embedded applications.\n78 5.5 Comparison with Control-C\nAll the control codes studied in our previous work on\nControl-C are accepted by our new compiler fully automati-\ncally, i.e., do not require the explicit use of single-region op-\nerations for dynamic memory management. Perhaps moreimportantly, the applications with Case 2 and Case 3 pools(Table 2) and many of those with Case 1 pools would bevery di\ufb03cult to implement with the single-region restrictionof Control-C. Moreover, since all the programs use command\nline arguments and most use other strings and I/O library\ncalls, none of them would accepted by the array boundschecks in Control-C. Thus, the new heap analysis and theimproved array access checks help to support a much largerclass of embedded codes than our previous work, and do so\nwithout program annotations.\n6. RELATED WORK\nThe broad approach of our work has been to identify\nminimal semantic restrictions on imperative programs andto develop new compiler techniques that together permitcomplete static checking of memory safety, without runtime\nchecks or garbage collection. To our knowledge no other\nprograming language or compiler system achieves this goalfor any non-trivial class of programs . We believe our re-\nsults show that we have achieved the goal for a signi\ufb01cantsubclass of embedded C programs, and the subclass is quite\nbroad if array bounds checks are ignored.\nSeveral alternative approaches have been taken to elim-\ninate speci\ufb01c types of runtime overheads, and we compareour approach with those below.\nThe Real-Time Speci\ufb01cation for Java (RT Java) [4] en-\nables programmers to avoid garbage collection entirely for\nsubsets of the heap by providing three additional types\nofMemoryArea s that are not garbage collected. Runtime\nchecks are required for ensuring safety of references betweenthe di\ufb00erent areas. Of these, the ScopedMemory type de-\n\ufb01nes nested (i.e., scoped) regions for dynamic allocation. Itis much more restrictive and has more runtime overheads\nthan our pools: memory can only be allocated from the\ncurrent region, it requires the programmer to specify regionentry/exit points, and perhaps most importantly, it requiresruntime checks to ensure that there are no references fromobjects in an outer scoped region (or from a di\ufb00erent typeof memory area) to an inner one [4]. Finally, RT Java also\ninherits the other runtime checking needs of standard Java\nsuch as for arrays, null pointer checks and type coercions.\nReal time garbage collection techniques (e.g., see [2] and\nthe references therein) use incremental collection methodsto reduce the unpredictability of garbage collection. Such\ntechniques can incur fairly high memory overhead to achieve\nacceptable real time behavior, up to 2.5 times the actualspace consumption of a program in recent work [2].\nAs an alternative to garbage collection, several recent lan-\nguages (e.g., RT Java [4], Cyclone [13, 11], and others [9, 5])have adopted mechanisms for region-based memory man-\nagement. These languages disallow direct deallocation of\nitems within a region in order to ensure program safety. Asdiscussed in the Introduction, these languages have two keydisadvantages relative to our work: (a) they generally re-quire extensive programmer annotations to identify regions;and (b) they provide no mechanisms to free or reuse memory\nwithin a region, so that data structures that shrink and grow(with non-nested object life times) must be put into a sepa-\nrate garbage-collected heap or may incur a potentially large\nincrease in memory consumption. (e.g., Cyclone and RTJava both include a separate garbage collected heap.) Au-tomatic region inference [25, 11] can eliminate or mitigatethe \ufb01rst but not the second, and has only been successfulfor type-safe languages without explicit deallocation.\nIn contrast to these approaches, we infer regions auto-\nmatically, we use no garbage collection, we permit explicitdeallocation of individual data items within regions, and weensure program safety through a combination of using ho-mogeneous regions and additional static analysis. There aretwo potential disadvantages in our work, however. We do\nnot prevent certain kinds of errors such as dangling pointer\nreferences (this is irrelevant for correct programs). Second,we rely heavily on interprocedural analysis (many of the an-notations in Cyclone and other languages are designed toavoid this need), but we retain the bene\ufb01ts of separate com-pilation by performing all our analysis at link-time (a key\nadvantage of using the LLVM compilation framework [16]).\nBoyapatiet al.[5] present a static type system combining\nownership types with region types, to eliminate the run-time checks needed for ensuring safe region deallocation inRT Java. As a region-based language, they have the samedi\ufb00erences from our work as discussed above. They pro-\nvide an additional mechanism based on \u201csub-regions\u201d of a\nregion for sharing region data safely across threads, usingreference counts to reclaim the data. We do not supportmulti-threaded applications so far.\nLinear types and alias types [6, 28, 7, 8] have been used\nto statically prove memory safety in the presence of explicit\ndeallocation of objects. They achieve this primarily with se-vere restrictions on aliases in a program, which so far havenot proved practical for realistic programs. One of theselanguages, Vault [7], also uses such a type system (muchmore successfully) to encode many important correctness\nrequirements for other dynamic resources within an appli-\ncation (e.g., \ufb01le handles and sockets). It would be very at-tractive to use Vault\u2019s mechanisms within our programmingenvironment to statically check key correctness requirementsof system calls and trusted libraries.\nA valuable strategy for compiler-based secure and reliable\nsystems is Proof-Carrying Code (PCC) [21]. The bene\ufb01t of\nPCC is that the safety checking compiler (usually a complex,unreliable system) can be untrusted, and only a simple proofchecker (which can be made much more reliable) is requiredwithin the trusted code base. Fundamentally, PCC does notchange what aspects of a program require static analysis and\nwhat require runtime checking \u2013 that still depends on the\nlanguage design and compiler capabilities. Thus, PCC isorthogonal to our work, and could be valuable for takingour safety-checking compiler outside the trusted code base.\nThere has been extensive work on static elimination of ar-\nray bounds checks (e.g., see [3, 27]), but the goal of that work\nis generally to eliminate a subset of bounds checks since com-plete elimination is impossible for standard languages. Incontrast, we impose carefully chosen language restrictions toenable compiler analysis to eliminate such checks entirely inconforming programs. Our previous work [15] discusses how\nthe interprocedural bounds checking algorithm presented\nthere compares with related work. Wagner et al.have de-\nveloped a tool for detection of bu\ufb00er overrun vulnerabili-ties in general C codes. Their analysis is necessarily impre-\n79 cise, however, both in terms of generating constraints (\ufb02ow-\ninsensitive) and solving them, resulting in many false pos-\nitives. In contrast, we use a more precise context-sensitiveanalysis and a more rigorous constraint solver.\n7. CONCLUSIONSAND FUTURE WORK\nIn this paper, we have described a set of semantic restric-\ntions and compiler techniques that together enable 100%static checking of memory safety for a signi\ufb01cant class oftype-safe embedded programs. The semantic restrictions\nare de\ufb01ned on a low-level language-independent type sys-\ntem and instruction set, and implemented in a language-independent, link-time compiler framework.\nThe key new result in this work is to show how an Auto-\nmatic Pool Allocation transformation allows us to ensure the\nsafety of dynamic memory management and pointer usage\nusing static checking alone (i.e., without garbage collectionor runtime checks on memory operations) and without any\nnew syntax. The compiler analysis helps to pinpoint the in-frequent case where certain data structures could experiencean increase in memory consumption. Our results show that\nthese techniques allow us to check heap and pointer safety\nfor all 17 embedded programs we studied. Our previoustechniques for eliminating null pointer checks and for stacksafety are also very e\ufb00ective for nearly all these programs,but our current analysis for checking array references can docomplete checking for only half the benchmarks we studied.\nOverall, we believe that codes certi\ufb01ed as safe by our com-\npiler can execute as fast as the those compiled by a native Ccompiler, while guaranteeing memory safety. Furthermore,we usually require minimal, simple, and completely portablerewriting of existing C programs to make them conform toour restrictions (often improving over the original!).\nThere are some key steps remaining before we can achieve\nour long term goal of a secure, low-overhead programmingenvironment based on the techniques above. First, we mustexplore better language and compiler support for complexarray operations. Second, we must provide a robust and\ufb02exible runtime environment with mechanisms to enforce\ncorrect usage of system calls and runtime libraries. Finally,\nwe must develop an architecture that tolerates bugs in thenecessarily complex compiler and runtime system.\n8. REFERENCES\n[1] T.M.Austin,S.E.Breach,andG.S.Sohi.E\ufb03cient\ndetectionofallpointerandarrayaccesserrors.In Proc.\nSIGPLAN \u201994 Conf. on Programming Language Design\nand Implementation ,Orlando,FL,June1994.\n[2] D.Bacon,P.Cheng,andV.Rajan.Areal-timegarbage\ncollectorwithlowoverheadandconsisitentutilization.In\nProc. 30th ACM Symp. Principles of Programming\nLanguages (POPL03) ,Jan.2003.\n[3] R.Bodik,R.Gupta,andV.Sarkar.ABCD:eliminating\narrayboundschecksondemand.In SIGPLAN Conf. on\nProg. Lang. Design and Implementation ,June2000.\n[4] G.BollellaandJ.Gosling.Thereal-timespeci\ufb01cationfor\nJava. Computer,33(6):47\u201354,2000.\n[5] C.Boyapati,A.Salcianu,W.Beebee,andM.Rinard.\nOwnershiptypesforsaferegion-basedmemory\nmanagementinreal-timejava.In SIGPLAN Conference on\nProgramming Language Design and Implementation ,2003.\n[6] K.Crary,D.Walker,andG.Morrisett.Typedmemory\nmanagementinacalculusofcapabilities.In Conference\nRecord of POPL 99: The 26th ACM SIGPLAN-SIGACTSymposium on Principles of Programming Languages, San\nAntonio, Texas ,pages262\u2013275,NewYork,NY,1999.[7] R.DeLineandM.Fahndrich.Enforcinghigh-levelprotocols\ninlow-levelsoftware.In Proc. SIGPLAN Conf. on\nProgramming Language Design and Implementation ,\nSnowbird,UT,June2001.\n[8] M.FahndrichandR.DeLine.Adoptionandfocus:\nPracticallineartypesforimperativeprogramming.In Proc.\nSIGPLAN Conference on Programming Language Design\nand Implementation ,June2002.\n[9] D.GayandA.Aiken.Memorymanagementwithexplicit\nregions.In SIGPLAN Conference on Programming\nLanguage Design and Implementation ,pages313\u2013323,\nMontreal,Canada,June1998.\n[10] J.Gosling,B.Joy,G.Steele,andG.Bracha. The Java\nLanguage Speci\ufb01cation .SunMicrosystems,2000.\n[11] D.Grossman,G.Morrisett,T.Jim,M.Hicks,Y.Wang,\nandJ.Cheney.Region-basedmemorymanagementin\ncyclone.In Proc. SIGPLAN Conf. on Programming\nLanguage Design and Implementation ,June2002.\n[12] M.R.Guthaus,J.S.Ringenberg,D.Ernst,T.M.Austin,\nT.Mudge,andR.B.Brown.Mibench: Afree,\ncommerciallyrepresentativeembeddedbenchmarksuite.In\nIEEE 4th Annual Workshop on Workload\nCharacterization ,Austin,TX,Dec.2001.\n[13] T.Jim,G.Morrisett,D.Grossman,M.Hicks,J.Cheney,\nandY.Wang.Cyclone: Asafedialectofc.In Proc.\nUSENIX Annual Technical Conference ,June2002.\n[14] W.Kelly,V.Maslov,W.Pugh,E.Rosser,T.Shpeisman,\nandD.Wonnacott.TheOmegaLibraryInterfaceGuide.\nTechnicalreport,ComputerScienceDept.,U.Maryland,\nCollegePark,Apr.1996.\n[15] S.Kowshik,D.Dhurjati,andV.Adve.Ensuringcode\nsafetywithoutruntimechecksforreal-timecontrolsystems.\nInProc. 2002 Conference on Compilers, Architecture and\nSynthesis for Embedded Systems ,Grenoble,Oct2002.\n[16] C.Lattner.LLVM:Aninfrastructureformulti-stage\noptimization.Master\u2019sthesis,ComputerScienceDept.,\nUniversityofIllinoisatUrbana-Champaign,Urbana,IL,\nDec2002. Seehttp://llvm.cs.uiuc.edu .\n[17] C.LattnerandV.Adve.AutomaticPoolAllocationfor\nDisjointDataStructures.In Proc. ACM SIGPLAN\nWorkshop on Memory System Performance ,Berlin,\nGermany,Jun2002.\n[18] C.LattnerandV.Adve.Datastructureanalysis: An\ne\ufb03cientcontext-sensitiveheapanalysis.Tech.Report\nUIUCDCS-R-2003-2340,ComputerScienceDept.,Univ.ofIllinoisatUrbana-Champaign,Apr2003.\n[19] C.Lee,M.Potkonjak,andW.H.Mangione-Smith.\nMediabench: Atoolforevaluatingandsynthesizing\nmultimediaandcommunicatonssystems.In International\nSymposium on Microarchitecture ,pages330\u2013335,1997.\n[20] P.LevisandD.Culler.Mate: Atinyvirtualmachinefor\nsensornetworks.In International Conference on\nArchitectural Support for Programming Languages andOperating Systems, San Jose, CA, USA ,Oct.2002.\n[21] G.C.Necula.Proof-carryingcode.In P r o c .o ft h e2 4 t h\nACM SIGPLAN-SIGACT Symposium on Principles ofProgramming Langauges (POPL \u201997) ,Paris,Jan.1997.\n[22] G.C.Necula,S.McPeak,andW.Weimer.Ccured:\nType-saferetro\ufb01ttingoflegacycode.In Proc. 29th ACM\nSymp. Principles of Programming Languages (POPL02) ,\nLondon,Jan.2002.\n[23] L.Sha.Dependablesystemupgrades.In Proceedings of\nIEEE Real Time System Symposium ,1998.\n[24] L.Sha.Usingsimplicitytocontrolcomplexity. IEEE\nSoftware,July/August2001.\n[25] M.TofteandL.Birkedal.Aregioninferencealgorithm.\nACM Trans. Prog. Lang. Sys. ,20(1),1998.\n[26] M.TofteandJ.-P.Talpin.Region-basedmemory\nmanagement. Information and Computation ,pages\n132(2):109\u2013176,Feb.1997.\n[27] D.Wagner,J.S.Foster,E.A.Brewer,andA.Aiken.A\n\ufb01rststeptowardsautomateddetectionofbu\ufb00eroverrun\nvulnerabilities.In Network and Distributed System Security\nSymposium,pages3\u201317,SanDiego,CA,February2000.\n[28] D.WalkerandG.Morrisett.Aliastypesforrecursivedata\nstructures. Lecture Notes in Comp. Sci. ,vol.2071,2001.\n80 ",
        "document_type": "research_paper",
        "owner": "Chris Lattner",
        "created_at": "2025-02-28T16:22:36.196048",
        "metadata": {
            "ai_analysis": {
                "originality_score": 0.85,
                "key_concepts": [
                    "memory safety",
                    "embedded systems",
                    "compilers",
                    "programming languages",
                    "static analysis",
                    "security",
                    "region management",
                    "automatic pool allocation"
                ],
                "potential_ip_aspects": [
                    "protection of intellectual property",
                    "enforcement of memory safety without new language syntax",
                    "avoidance of runtime checks and garbage collection"
                ]
            }
        },
        "hash": "92f0cf713ad0f6242401275fed984a5de6118a6487aef08716d13ef0ceec09f4"
    },
    "3f140ad7-e862-484e-ac19-e3dd4ff72b47": {
        "document_id": "3f140ad7-e862-484e-ac19-e3dd4ff72b47",
        "content": "Memory SafetyWithoutRuntimeChecks or Garbage\nCollection\u2217\nDinakar Dhurjati Sumant Kowshik Vikram Adve Chris Lattner\nUniversityof Illinois at Urbana-Champaign\n{dhurjati,kowshik,vadve,lattner }@cs.uiuc.edu\nABSTRACT\nTraditional approaches to enforcing memory safety of pro-\ngrams rely heavily on runtime checks of memory accessesand on garbage collection, both of which are unattractive forembedded applications. The long-term goal of our work is\nto enable 100% static enforcement of memory safety for em-\nbedded programs through advanced compiler techniques andminimal semantic restrictions on programs. The key resultof this paper is a compiler technique that ensures memorysafety of dynamically allocated memory without program-\nmer annotations, runtime checks, or garbage collection ,a n d\nworks for a large subclass of type-safe C programs. Thetechnique is based on a fully automatic pool allocation (i.e.,region-inference) algorithm for C programs we developedpreviously, and it ensures safety of dynamically allocatedmemory while retaining explicit deallocation of individual\nobjects within regions (to avoid garbage collection). For a\ndiverse set of embedded C programs (and using a previoustechnique to avoid null pointer checks), we show that we areable to statically ensure the safety of pointer and dynamicmemory usage in all these programs . We also describe some\nimprovements over our previous work in static checking of\narray accesses. Overall, we achieve 100% static enforcement\nof memory safety without new language syntax for a signif-icant subclass of embedded C programs, and the subclass ismuch broader if array bounds checks are ignored.\nCategories and Subject Descriptors\nC.3 [ComputerSystemsOrganization ]: Special-Purpose\nand Application-based Systems; D.3 [ Software ]: Program-\nming Languages; D.4.6 [ Software ]: Operating Systems\u2014\nSecurity and Protection\nGeneral Terms\nSecurity, Languages\n\u2217This has been sponsored by the NSF Embedded Systems\nprogram under award CCR-02-09202 and in part by an NSFCAREER award, EIA-0093426 and ONR, N0004-02-0102.\nPermission to make digital or hard copies of all or part of this work for\npersonal or classroom use is granted without fee provided that copies are\nnot made or distributed for pro\ufb01t or commercial advantage and that copies\nbear this notice and the full citation on the \ufb01rst page. Tocopy otherwise, torepublish, topostonserversortoredistribute tolists,requires priorspeci\ufb01c\npermission and/or a fee.\nLCTES\u201903, June 11\u201313, 2003, San Diego, California, USA.\nCopyright 2003 ACM 1-58113-647-1/03/0006 ...\n$5.00.Keywords\nEmbedded systems, compilers, programming languages, static\nanalysis, security, region management, automatic pool allo-cation.\n1. INTRODUCTION\nCurrent and future embedded systems demand increas-\ning software \ufb02exibility, including the ability to upgrade orintroduce software modules into existing applications botho\ufb04ine and during active operation. Such software upgradesare becoming increasingly common for small consumer de-\nvices, and are expected to be important even for more con-\nstrained systems such as embedded control systems [23, 24]and sensor networks [20]. One of the key requirements forenabling dynamic software upgrades is to ensure that newsoftware modules or applications do not compromise the safeand correct functioning of an embedded device. One part\nof this problem is ensuring the memory safety of embedded\nsoftware, i.e., to guarantee that an upgraded software mod-ule cannot corrupt the code or data of its host application.(The term \u201cmemory safety\u201d is de\ufb01ned in Section 2.)\nUnfortunately, it appears that current language or system\napproaches for ensuring memory safety require signi\ufb01cant\noverheads in terms of runtime checks and garbage collec-\ntion. Safe languages like Java [10], Modula-3, ML, Safe-C [1], Cyclone [13] and CCured [22] use a variety of runtime\nchecks before individual memory operations such as bounds\nchecks for array references, null pointer references, and typeconversions, and they rely on garbage collection to ensure\nthe safety of references to dynamically allocated memory.\nThe overheads of runtime checking are quite signi\ufb01cant: lan-guages like SafeC, CCured, Cyclone and Vault have reportedslowdowns ranging from 20% up to 3x for di\ufb00erent applica-tions [1, 22, 11, 7].\nMany types of embedded software must operate under\nstringent energy, memory, and processing power limitations,and often under hard or soft real-time constraints as well.The runtime overheads of safety checks and both the over-heads and the potential unpredictability of garbage collec-tion are unattractive for such software [4].\nThe long-term goal of our work is to ensure memory safety\nfor embedded software while eliminating or greatly mini-mizing the need for runtime checks and garbage collection.Because this goal is impossible with ordinary language fea-tures such as arbitrary dynamic memory allocation, aliases,and array references, our strategy is to impose (minimal)\nsemantic restrictions on programs necessary to achieve this\n69 goal with existing compiler technology, and to reduce these\nrestrictions by developing new compiler techniques.\nIn previous work, we addressed the limited class of real-\ntime control applications (which typically use very simpledata structures and memory management) by designing arestricted subset of the C language appropriate for such pro-grams. This language, which we called Control-C, imposed\nonerous restrictions on dynamic memory allocation, pointer\nusage, and array usage [15]. We showed that with theserestrictions, existing compiler technology can permit 100%\nstatic checking of memory safety for this language. Unlikereal-time control codes, however, other kinds of embeddedapplications use dynamically allocated memory and arrays\nin much more complex ways, and the restrictions in Control-\nC would preclude writing such applications.\nA major technical challenge for broader classes of embed-\nded applications is allowing \ufb02exible dynamic memory allo-cation and deallocation without runtime checks or garbagecollection. Proving statically that a general C program (for\nexample) never dereferences a freed pointer (the \u201cdangling\npointer\u201d problem) is undecidable.\nSeveral recent languages including Real-time Java [4],\nCyclone [13], Vault [7], and others [26, 9, 5] have intro-duced language mechanisms for region-based memory man-agement. In this approach, the heap is partitioned into sep-\narate regions and deallocation is only permitted on an entire\nregion at once. These mechanisms guarantee the safety ofpointer-based accesses to region data without garbage col-lection, but have two key disadvantages:\n(1) Converting programs to use region-based mechanisms\ndemands signi\ufb01cant manual e\ufb00ort, typically requiringregion annotations on pointer variables, function in-terfaces, and allocation sites.\n(2) These region management schemes disallow explicit\ndeallocation of individual objects, so data structures\nthat must shrink and grow frequently (and have ob-\njects with non nested life times) have to fall back ona separate garbage-collected heap [4, 11] to avoid po-tentially unbounded growth in unused memory.\nAutomatic region inference algorithms have been devel-\noped that solve the \ufb01rst issue completely or partially, butonly for languages with no explicit deallocation such asML [25] and Cyclone [11] (i.e., languages which would oth-erwise require garbage collection).\nRecently, we developed a fully automatic region inference\nalgorithm called Automatic Pool Allocation that works cor-rectly for C programs with explicit malloc and free(in-\ncluding non-type-safe programs) [17]. The transformationsolves both the problems above because it is fully automatic\nand retains explicit deallocation of individual objects within\nregions. Each pool holds objects of a single size, thus elimi-nating fragmentation within pools and enabling very fast al-location and deallocation. Unfortunately, allowing individ-ual object deallocation means that the transformation doesnotensure memory safety (it makes no attempt to eliminate\nor restrict dangling pointers).\nThe main result of the current work is to extend Au-\ntomatic Pool Allocation to ensure memory safety withoutrequiring runtime checks, while retaining the performanceand memory bene\ufb01ts of the original algorithm (includingfully automatic region management without language anno-\ntations, and explicit deallocation of objects within regions).The key to our approach is that we do notprevent uses of\ndangling pointers to freed memory (e.g., a read, write, or\nfree on an already freed storage location); instead, we en-sure statically that such operations cannot cause violationsof type safety or memory safety.\nThe speci\ufb01c contributions of this paper are as follows:\n(a) We show how to use the Automatic Pool Allocation\ntransformation to ensure the safety of references todynamically allocated memory. We use an interpro-\ncedural \ufb02ow analysis of the compiler-generated pool\noperations to pinpoint data structures for which ourapproach could lead to increased memory consumptionby the program. The analysis also identi\ufb01es pools forwhich individual object deallocation can be completely\neliminated, without increasing memory consumption.\n(b) We extend our previous program restrictions and com-\npiler analysis for ensuring array access safety in order\nto support some common features that were disallowed\nbefore, including string manipulation, standard I/Ooperations, and argument vectors.\n(c) We evaluate how e\ufb00ective the new techniques in this\npaper (and other compiler safety checks retained fromthe previous work) are in permitting static checkingof memory safety, using a diverse collection of embed-ded programs from two widely used benchmark suites,\nMiBench [12] and MediaBench [19].\nOur experimental results show that we are able to stati-\ncally ensure the safety of pointer and dynamic memory us-agein all these programs . Our compiler analysis identi\ufb01es\nspeci\ufb01c data structures in two of these programs where our\nmemory management strategy could lead to some (probably\nsmall) potential increase in memory consumption. Overall,the approach promises safe dynamic memory managementwithout the overheads of runtime checks, and with negligiblemanual programmer e\ufb00ort. We believe that this is a majorstep towards achieving our long-term goal of 100% static\nenforcement of memory safety for embedded programs.\nOur results also show that two other essential techniques\ndeveloped in our previous work are adequate for the pro-grams studied here: a novel memory initialization strategyto eliminate runtime checks for null pointer references un-der a speci\ufb01c system assumption, and a compiler analysis for\nlifetimes of stack-allocated data. The former is su\ufb03cient for\nall our programs (and necessary for most), while the latterworks successfully for 16 out of 17 programs. Proving thesafety of array references, however, remains a major chal-lenge in achieving our long-term goal. With the extensions\nabove, we are able to prove the safety of array references in 8\nout of 17 of these programs. We draw some ideas for futurelanguage and compiler mechanisms that might succeed forthe other programs.\nThe rest of this paper is organized as follows. The next\nsection de\ufb01nes what we mean by memory safety and static\nchecking, brie\ufb02y describes our previous work on static safety\nchecking for real-time control systems, and summarizes theassumptions we make about programs and systems in ourcurrent work. Section 3 describes the language restrictionsand compiler techniques for ensuring safety of pointer ref-erences and heap management. Section 4 does the same\nfor array references. Section 5 describes our experiments\n70 evaluating the e\ufb00ectiveness of our techniques in supporting\ndi\ufb00erent classes of embedded applications. Section 6 com-\npares our work with previous work on providing programsafety through static techniques. Section 7 concludes witha summary of our results and suggests directions for furtherresearch.\n2. DEFINITIONS,PRIORWORK,ANDAS-\nSUMPTIONS\nFor the purposes of this work, we de\ufb01ne a software entity\n(a module, thread, or complete program) to be memory-\nsafeif (a) it never references a memory location outside the\naddress space allocated by or for that entity, and (b) it never\nexecutes instructions outside the code area created by thecompiler and linker within that address space. In practice,to enable static enforcement of the above requirements, wemust enforce stronger restrictions, e.g., strict type rules forall operations, limited type conversions, and in-bounds array\naccesses. The stronger restrictions also help to detect many\nkinds of errors at compile-time rather than at runtime.\nBy \u201cstatic enforcement\u201d or \u201cstatic checking\u201d of memory\nsafety, we mean that the compiler must ensure memorysafety without relying on garbage collection and without\nintroducing anyruntime checks before program operations\n(e.g., null pointer, array bounds, or type conversion checks).Some runtime support is still necessary, especially initializa-tion of global or dynamically allocated storage, and somesystem assumptions for error recovery described later.\nMany ordinary constructs in modern languages (particu-\nlarly array accesses and complex pointer-based data struc-\ntures) make it impossible to ensure memory safety via staticchecking alone. We therefore choose to impose some restric-tions on programs to make static checking possible. To makeit as simple as possible to modify existing embedded code toconform to our restrictions, we avoid adding anynew lan-\nguage mechanisms or syntax. Instead, we impose usage (i.e.,\nsemantic) restrictions that can be de\ufb01ned within the frame-work of an existing language, and checked by a compiler.\nAlthough our experiments focus on C programs in this\npaper, our semantic restrictions are de\ufb01ned in low-levellanguage-independent terms, and our safety checking com-\npiler is implemented entirely in a language-independent\ncompiler infrastructure called LLVM (Low Level VirtualMachine) [16]\n1. These features, together with the lack of any\nnew source-level constructs, imply that our safety-checkingstrategy can be used for programs in any source-level lan-\nguage compiled to LLVM object code.\n2.1 Control-C: MemorySafety forReal-Time\nControl Codes\nThe Control-C language de\ufb01ned in our previous work [15]\nimposed many semantic restrictions on C programs, andadded one new language mechanism for manual region al-location (described below). The goal was to enable 100%static checking of memory safety for real-time control codesusingexisting compiler techniques. We brie\ufb02y describe that\nlanguage to provide a basis for understanding how new com-\npiler techniques in the current work can eliminate the needfor some of these restrictions.\n1LLVM de\ufb01nes a simple, fully typed instruction set based on\nStatic Single Assignment (SSA) form as the input code rep-resentation in order to enable compile-time, link-time andruntime optimization of programs. See llvm.cs.uiuc.edu .There were 3 classes of restrictions in Control-C:\n\u007fType safety : Input programs had to be strongly typed.\nThese restrictions are retained in our current work.\n\u007fA\ufb03ne Expressions for Accessing Arrays : Control-C\nimposed restrictions on array index expressions andloop bounds so that the net e\ufb00ect is to produce an\na\ufb03ne relationship between the e\ufb00ective address ex-\npression and the size expression for each array dimen-sion. It also disallowed most common library func-tions and string operations. The a\ufb03ne requirement isretained in this work but a number of trusted library\nfunctions and string operations are now permitted.\n\u007fSingle-Region Dynamic Memory Allocation : Control-\nC imposed onerous restrictions on dynamic memory\nallocation and pointer usage, all of which have been\neliminated in the current work :\n\u2013Heap allocation was restricted to a single region\nat a time , and the entire region (i.e., all heap ob-\njects) had to be deallocated simultaneously.\n\u2013Every time the region was freed, all scalar point-\ners variables (local and global) had to be re-initialized before their next use.\n\u2013Structures or arrays containing pointers had to\nbe allocated dynamically, either on the heap oron the stack using C\u2019s alloca intrinsic.\nWe showed that these restrictions are adequate for many\nreal-time control algorithms, which tend to use very simpledata structures and memory management. They are clearly\ninadequate for broader classes of embedded programs. Elim-\ninating these restrictions and retaining static checking ofmemory safety requires new compiler techniques, particu-larly for array bounds checking and for heap and pointersafety. The current work primarily focuses on the latter,\nwhile making some simple improvements to the former.\n2.2 Assumptions of this Work\nThe system assumptions of the current work, plus the\nbasic language restrictions for type safety and pointer safetyare summarized below. The language restrictions for arraysafety are described in later sections.\nFirst, we make some assumptions about the runtime en-\nvironment. We assume that certain runtime errors are safe,i.e., the runtime system can recover from such errors bykilling the applet, thread, or process executing the untrustedcode. We assume a safe runtime error is generated if either\nthe stack or the heap grows beyond the available address\nspace. We assume the system has a reserved address range\nand any access to these addresses causes a safe runtime error,typically triggered by a page fault handler or by a reservedaddress range in hardware on systems without virtual mem-ory management.\n2If this is not available, some null pointer\nchecks must be inserted in the code, as described later.\nWe assume that certain standard library functions and\nsystem calls are trusted and can be safely invoked by theuntrusted code (calls whose arguments must be checked arediscussed in Section 4). We assume (and check) that the\n2For example, in standard Linux implementations, the high\nend of the process address space is reserved for the kernel,typically 1 GB out of 4 GB.\n71 source code of all other functions is available to the compiler.\nWe also require that the program be single-threaded.\nWe retain the basic type rules of Control-C, summarized\ninformally below. We assume a low-level type system in-cluding a set of primitive integer and \ufb02oating point types,arrays, pointers, user-de\ufb01ned records (structures), restrictedunion types, and functions.\n(T1) All variables, assignments, and expressions must be\nstrongly typed.\n(T2)C a s t stoa pointer type from any other type are disal-\nlowed. (Certain pointer-to-pointer casts for compati-\nble targets are considered safe, however.)\n(T3) A union can only contain types that can be cast to\neach other, e.g., a union cannot include a pointer and\na non-pointer type.\nEnforcing the above rules is trivial in LLVM [16], where all\noperations are typed and only an explicit castinstruction\ncan be used to perform any type conversion.\nWe also retain some rules required for ensuring pointer\nsafety, which are discussed in Section 3:\n(P1) Every local pointer variable must be initialized before\nbeing referenced, i.e., before being used or having its\naddress taken .\n(P2) Any individual data type (i.e., not an array) should be\nno larger than the size of the reserved address range.\n(P3) The address of a stack location cannot be stored in a\nheap-allocated object or a global variable, and cannotbe returned from a function.\n3. SAFETY OFPOINTER REFERENCES\nIn a language without garbage collection, and with the\ntype restrictions T 1\u2013T 3 above, there are three key ways\nin which pointer usage can lead to unsafe memory behavior:(a) Uninitialized pointer variables (either scalars or elements\nof aggregate objects) could be used to access invalid memory\naddresses. (b) A pointer into the stack frame of a functionthat is live after the function returns could be used to accessan object of a di\ufb00erent type (i.e., to violate type safety). (c)A pointer to a freed memory object (a \u201cdangling pointer\u201d)\ncould be used to access an object of a di\ufb00erent type allocated\nlater.\nThese three problems must be detected and disallowed at\ncompile-time or safely tolerated at runtime without intro-ducing checks for individual memory references. We exam-ine each of these conditions in turn in the following subsec-\ntions.\n3.1 Uninitialized pointers\nOur compiler prevents the \ufb01rst error above (due to unini-\ntialized pointer values) in the same way as in our previouswork, through a combination of static analysis and mini-\nmal runtime support [15]. We describe this brie\ufb02y here for\ncompleteness.\nFirst, we use a standard global data\ufb02ow analysis to\ncheck ruleP1above, which requires that all automatic\nscalar pointers must be initialized within their parent func-tion explicitly before they are dereferenced or their address\ntaken [15].Detecting uninitialized values for global variables and for\npointers within dynamically allocated data (e.g., structure\n\ufb01elds or arrays), is di\ufb03cult at compile-time. In order toavoid runtime null pointer checks, we initialize all uninitial-ized global scalar pointers and all pointer \ufb01elds in dynami-cally allocated data structures at allocation time to point tothe base of the reserved address range (analogous to the ini-\ntialization of \ufb01elds in Java). Pointer \ufb01elds in stack-allocated\nvariables of aggregate types are also initialized to the samevalue. Finally, the constant 0 used in any pointer-type ex-pression is replaced with the same value. Rule P2above\nspeci\ufb01es that the size of any individual structure type\n3can-\nnot exceed the size of the reserved address range. With this\nrule, the above initialization ensures that the e\ufb00ective ad-\ndress for the load of any scalar variable or structure \ufb01eldusing an uninitialized pointer will fall within the reservedaddress range, thus triggering a safe runtime error. If areserved address range is unavailable or the structure sizerestriction above is unacceptable, then runtime checks for\nnull pointer references would be required.\n3.2 Stack safety\nProblem (b) above potentially arises when the address of\na local variable (i.e., a pointer into the current stack frame)is made accessible after the function returns. To avoid thisproblem, many type-safe languages like Java disallow taking\nthe address of local variables. We choose to be less restric-\ntive: we only disallow placing the address of a stack locationin any heap location or global variable, or returning it di-rectly from a function (rule P3above).\nEnforcing this rule requires sophisticated compiler tech-\nnology, but no more than that required to perform Auto-\nmatic Pool Allocation for enforcing heap safety. In par-\nticular, we use Data Structure Analysis , a \ufb02ow-insensitive,\ncontext-sensitive (but very fast), interprocedural analysisthat computes a Data Structure Graph for each proce-\ndure [18]. This is a directed graph of all the memory objectsaccessible within a procedure, along with their types, their\nstorage class (stack, heap, global, formal parameter, return\nvalue, or local scalar temporaries), and the \u201cpoints-to\u201d linksbetween them. The graph for each function includes reach-able objects passed in from callers or returned from callees.\nRuleP3can now be enforced using a simple traversal\nof the Data Structure Graph for each function, checking\nwhether any stack-allocated object is reachable from thefunction\u2019s pointer arguments, return node or globals.\n3.3 Heap Safety\nThe third error above, that of detecting unsafe accesses\nto freed memory, is a particularly challenging problem for alanguage with explicit memory deallocation. The example\nin Figure 1 illustrates the challenges. Function fcalls g,\nwhich \ufb01rst creates a linked list of 10 nodes, initializes them,a n dt h e nc a l l s hto do some computation. gthen frees all\nof the nodes except the head and then returns. fthen uses\na dangling pointer reachable from the head. In such code,\nit is extremely hard for any compiler to statically identify\nwhich references (if any) may be unsafe and which are not.Moreover, consider h(), which allocates one node and frees\n3An array does not need this size restriction. An uninitial-\nized pointer used as an array reference will be caught by thearray bounds checker since the array will have no known sizeexpression.\n72 one node of the list 104times. Eliminating explicit frees\nby using region allocation (such as in Control-C, Cyclone,\nor other languages with nested regions) would increase theinstantaneous memory consumption of the program by 10\n4\n* sizeof(struct s) bytes because the region holding list\nitems can be freed only after exiting the function f.\nf() {\n...g(p);\n// p->next is dangling\np->next->val = ... ;\n}g(struct s *p) {\ncreate_10_Node_List(p);\ninitialize(p);h(p);free_all_but_head(p);\n}\nh(struct s *p) {\nfor (j=0; j < 100000; j++) {\ntmp = (struct s*) malloc(sizeof(struct s));insert_tmp_to_list(p,tmp);\nq = remove_least_useful_member(p);\nfree(q);\n}\n}\nFigure1: Pointersafetyandpoolallocationexample\nThe key principle underlying our approach is the follow-\ning:(Type homogeneity principle) If a freed memory block\nholdingasingleobjectweretobereallocatedtoanotherobjectof the same type and alignment, then dereferencing dangling\npointers to the previous freed object cannot cause a type vi-\nolation. This principle implies that to guarantee memory\nsafety, we do not need to prevent dangling pointers or theirusages in the source \u2013 we just need to ensure that theycannot be dereferenced in a type unsafe manner. The prin-ciple allows correct programs ( i.e.programs with no uses of\ndangling pointers), to work correctly without any runtime\noverhead. Programs with dangling pointer errors will exe-cute safely but we cannot (and do not need to) prevent sucherrors for these programs.\nUsing the above principle directly, one simple but imprac-\ntical solution is to separate the heap into disjoint pools for\ndistinct data types and never allow memory used for one\npool to be reused later for a di\ufb00erent pool. This is imprac-tical because it can lead to large increases in the instanta-neous memory consumption. The worst-case increase for aprogram with Npools would be roughly a factor of N\u22121,\nwhen a program \ufb01rst allocates data of type 1, frees all of it,\nthen allocates data of type 2, frees all of it, and so on.\nOur solution is essentially a more sophisticated applica-\ntion of this basic principle, using Automatic Pool Allocationto achieve type-homogeneous pools with much shorter life-times in order to avoid signi\ufb01cant memory increases as far\nas possible.\n3.3.1 Background: The Automatic Pool Allocation\nTransformation\nThe Automatic Pool Allocation transformation was de-\nveloped as a general compiler technique for enabling macro-\nscopic optimizations on logical data structures [17]. This\ntransformation introduces pool-based memory managementfor a subset of the disjoint data structures in an ordinary im-perative program that uses explicit allocation (e.g. malloc )\nand deallocation (e.g., free). It rewrites the allocation and\ndeallocation operations to use separate pools of memory for\neach logical data structure instance (e.g., a particular linkedlist or a graph) that is not exposed to unknown external\nfunctions. A pool is created before the \ufb01rst allocation for\nits data structure instance and destroyed at a point wherethere are no accessible references to data in the pool.\nWe use a pool allocation library with \ufb01ve simple op-\nerations: (a) poolinit(Pool** PP, TypeDesc* TD) cre-\nates a new pool for objects of the speci\ufb01ed type. (b)\npooldestroy(Pool* PP) destroys a pool and releases its re-\nmaining memory back to the system heap. (c) poolalloc\n(Pool* PP) and poolallocarray(Pool* PP, int N) allo-\ncate a single object or an array of Nobjects in the pool.\n(d)poolfree (Pool* PP, T* ptr) deallocates an object\nwithin the pool by marking its memory as available for real-\nlocation by poolalloc orpoolallocarray . The pool library\ninternally uses ordinary malloc andfreeto obtain memory\nfrom the system heap and return it when part of a poolbecomes unused or the pool is destroyed.\nThe pool allocation transformation operates as follows:\n1.Identify data structure (DS) instances : We traverse\nthe Data Structure Graph of each function (describedin Section 3.2) to identify maximal connected sub-graphs containing only heap nodes. Each such sub-graph represents a distinct heap-allocated data struc-ture.\n2.Identify where to create/destroy pools : For each pro-\ncedure, the DSG can be used to identify those data\nstructures that are not accessible after the procedure\nreturns (i.e., do not \u201cescape\u201d from the procedure to itscallers). For each such data structure, we insert callsto create and destroy pools of memory (one pool perdata type used in the data structure) at the entry andexit of the procedure.\n4In our running example, the\nlinked list does not escape from the procedure f()to\nits callers and so we create and destroy the pool forthe list in procedure f(), as shown in Figure 2.\n3.Transform (de)allocation operations and function in-\nterfaces : We transform all malloc and freecalls in\nthe original program to use the pool allocation ver-sions, as illustrated in function h(). For any function\ncontaining such operations on a pool created outside\nthe function, we add extra arguments to pass the ap-\npropriate pool pointers into the function (and do thesame for possible callers of such functions, and theircallers and so on).\n5This is illustrated by the functions\ng()and h()and their invocations in Figure 2.\nThe result of this transformation for type-safe programs\nis that all heap-allocated objects are assigned to type-homogeneous pools, disjoint data structure instances (asde\ufb01ned above) are assigned to distinct sets of pools, andindividual items are allocated and freed from the individ-ual pools at the same points that they were before. A pool\nis destroyed when there are no more live (i.e., reachable)\nreferences to the data in the pool.\n4Our pools do not require nested lifetimes. We could move\npoolinit later in the function and move the pooldestroy\nearlier or into a callee using additional \ufb02ow analysis, but wedo not do so currently.\n5Data Structure Analysis also identi\ufb01es the targets of func-\ntion pointers and constructs a call graph, allowing us tohandle programs with indirect calls and recursion.\n73 f() {\nPool *PP;poolinit(PP, struct s);...\ng(p, PP);\n// p->next is danglingp->next->val = ... ;\npooldestroy(PP);\n}g(struct s *p, Pool *PP) {\ncreate_10_Node_List(p, PP);\ninitialize(p);h(p, PP);\nfree_all_but_head(p, PP);\n}\nh(struct s *p, Pool *PP ) {\nfor (j=0; j < 100000; j++) {\ntmp = poolalloc(PP);\ninsert_tmp_to_list(p, tmp);q = remove_least_useful_member(p);\npoolfree(PP, q);\n}\n}\nFigure2: Exampleafterpoolallocationtransforma-\ntion\nNote that the transformation as described so far does not\nensure program safety . Explicit deallocation via ( poolfree )\ncan return freed memory to its pool and then back to thesystem, which can then allocate it to a di\ufb00erent pool. Dan-gling pointers to the freed memory could violate type safety.\n3.3.2 Exploiting PoolAllocationforHeapSafety\nThe basic principle of type homogeneity mentioned ear-\nlier can be applied to ensure program safety after the pool\nallocation transformation. Since our pools are already type-homogeneous, we simply need to ensure that the memorywithin some pool P\n1is not used for any other dynamically\nallocated data (either another pool P2or heap allocations\nwithin trusted libraries) until P1is destroyed. This can be\ndone easily by modifying the runtime library so that mem-\nory of a pool is not released to the system heap except bypooldestroy . This change can have the same disadvantage\nas the na \u00a8ive type-based pools \u2013 the memory requirement of\nthe program could increase signi\ufb01cantly.\nNote, however, that our pools are much more short-lived\nthan in the na \u00a8ive approach and are tied to dynamic data\nstructure instances in the program, not static types. Weexpect, therefore, that during the lifetime of a pool, themost important reuse of memory (if any) is within the pool\nrather than between the pool and other pools. Only thelatter causes any potential increase in memory consumption.\nNevertheless, any such increases are likely to be of signi\ufb01cant\nconcern to programmers of embedded systems.\nThe goal of our further analysis is to distinguish the sit-\nuations outlined above, and inform the programmer aboutdata allocation points where potential memory increases can\noccur. We can classify each pool Pinto three categories:\nCase 1 (No reuse): Between any poolfree for pool P\nand the pooldestroy for P, there are no calls to poolalloc\nfrom any pool including Pitself. In this case, there is no\nreuse of P\u2019s memory until Pis destroyed. Figure 3(a) illus-\ntrates this situation. Note that all poolfree calls to Pcan\nbeeliminated as a performance optimization . This is essen-\ntially static garbage collection for the pool since its memoryis reclaimed by the pooldestroy introduced by the compiler.\nCase 2 (Self-reuse): Between any poolfree operation\non pool Pand the call to pooldestroy for P,t h eo n l y\npoolalloc operations are to the same pool P.I nt h i sc a s e ,the only reuse of memory is within pool P, and the explicit\ndeallocation via poolfree ensures that no increase in the\nprogram\u2019s memory consumption will occur. This is illus-trated in Figure 3(b): after the \ufb01rst poolfree onp1there\nare new allocations in pool p1(via the function addItems ),\nbut not by any other pool.\nCase 3 (Cross-reuse): Between the \ufb01rst poolfree op-\neration on Pand the pooldestroy for pool P.t h e r e a r e\npoolalloc operations for other pools. Pool p1i nF i g u r e3 (c )\nfalls in this category because there are allocations from poolp2via the call to addItems(p2,t) . Our transformation in this\ncase may lead to increased memory consumption, and we re-q u i r et h i st ob ea p p r o v e db yt h ep r o g r a m m e rv i aac o m p i l e r\noption. In such situations, a programmer should be able\nto estimate the potential memory increase through manualanalysis or pro\ufb01ling. In practice, we expect the amount ofmemory released by one pool and used by another, beforethe \ufb01rst pool is destroyed, will be relatively small.\nNote that the pool in our running example of Figure 2 has\nonly self-reuse, and we can guarantee memory safety without\nany increase in memory consumption. Our experiments inSection 5 have produced very few instances of case 3, andin only 2 out of the 17 embedded codes we examined.\n3.3.3 CompilerImplementation\nThe compiler \ufb01rst applies the type checking, stack safety,\nand array safety analyses to the original program. It then\napplies Automatic Pool Allocation to transform the program\nas described earlier. We have modi\ufb01ed our runtime pool al-location library so it does not release free memory in a poolback to the system heap until the pool is destroyed. Thekey goal of the new compiler analysis is to identify situa-tions where this can lead to a potential increase in memory\nconsumption by categorizing pools as described above.\nCategorizing pools requires analyzing the potential order\nof execution of pool operations a c r o s st h ee n t i r ep r o g r a m ,\nusing an interprocedural control \ufb02ow analysis. AutomaticPool Allocation records information about the pools usedin each function and the locations of calls to poolalloc ,\npoolfree and pooldestroy inserted for each pool. Pool\npointers are passed between procedures but they are nototherwise copied and their address is never taken, so eachpool pointer variable within a function identi\ufb01es a uniquepool. Our current pool allocation transformation places thecalls to pooldestroy at the end of the function containing\nthe call to poolinit for that pool.\n6\nThe algorithm for identifying and categorizing reuse within\nand across pools is shown in Figure 4. We say a func-tion F(or a call site C) indirectly calls a pool operation\n(e.g., poolfree ) if it calls some function that may directly\nor indirectly call that operation. The sets FreeSites(F,P)\nand AllocSites(F,P) respectively identify the call sites\nwithin function Fthat directly or indirectly invoke poolfree\nand poolalloc on pool P.T h es e t s PoolsFreed(F) and\nPoolsAlloced(F) respectively are sets of incoming pools\n(i.e., formal pool pointer arguments to function F)f o rw h i c h\nFmay directly or indirectly call poolfree orpoolalloc .\nConsider \ufb01rst a single-procedure program containing calls\ntopoolfree ,poolalloc and pooldestroy . The analysis\nthen traverses paths from a poolfree for a pool to the\n6The algorithms described in this section can be easily modi-\n\ufb01ed if poolinit andpooldestroy calls are placed di\ufb00erently\nby Pool Allocation.\n74 p1 = poolinit(s);\nt = makeTree(p1);while(...) {\nprocessTree(p1,t);\nfreeSomeItems(p1,t);\n}\nfreeTree(p1,t);poolDestroy(p1);p1 = poolinit(s);\nt = makeTree(p1);while(...) {\nprocessTree(p1,t);\nfreeSomeItems(p1,t);\naddItems(p1,t); // self-reuse\n}\nfreeTree(p1,t);poolDestroy(p1);p1 = poolinit(s);\nt = makeTree(p1);while(...) {\nprocessTree(p1,t);\nfreeItems(p1,t);\naddItems(p1,t); // self-reuseaddItems(p2,t); // cross-reuse\n}\nfreeTree(p1,t);poolDestroy(p1);\n(a)Noreuse (case 1) (b)Self-reuse (case 2) (c)Self-andCross-reuse (case 3)\nFigure 3: Exampleillustrating3 typesof reuse behaviorfor a pool p1.\nunique pooldestroy of that pool, looking for all calls to\npoolalloc that appear on such a path. This is shown as\nroutine AnalyzeFunction in Figure 4. (It is easy to handle\nall pools in a single linear-time traversal of the Control FlowGraph, but the version in the \ufb01gure is much easier to un-derstand.) Each pool is then categorized according to whatinstances of poolalloc , if any, are found on such paths.\nConsider next an input program without recursion. The\nalgorithm then makes a bottom-up traversal of the callgraph, computing the four kinds of sets above for eachfunction. The bottom-up traversal ensures that the setsPoolsFreed(C) and PoolsAlloced(C) will be computed for\nall possible callees Cof a function F, before visiting F.\nTo compute the sets for F, we visit each call site SinF\nand add this call to FreeSites(F,P) if it causes an invo-\ncation of poolfree(P) ,a n dt o AllocSites(F,P) similarly.\nWe also add each pool so encountered to PoolsFreed(F) or\nPoolsAlloced(F) . We can now invoke AnalyzeFunction(F)\ndirectly to classify all pools in F.N o t et h a t AnalyzeFunction(F)\nmakes no distinction between local and indirect calls to\npoolfree /poolalloc for pool Psince both kinds of call sites\nare included in FreeSites(F,P) and AllocSites(F,P) .\nTo handle recursive and non-recursive programs uni-\nformly, we actually perform the bottom-up traversal on theStrongly Connected Components (SCC\u2019s) of the call graph.\nWithin each SCC, we use a simple iterative algorithm in\nwhich the sets are propagated from a function to its callsiteswithin the SCC until the sets FreeSites(F,P) and\nAllocSites(F,P) stabilize for all functions Fin the SCC\nand every pool P. Once they have stabilized, the sets can be\npropagated from each function in the SCC to every call site\nof that function outside the SCC. AnalyzeFunction is then\napplied to each function Fin the current SCC as explained\nearlier.\n4. ARRAYRESTRICTIONS\nIn general, array bounds checking in general programs is\nundecidable. In our previous work [15], we designed lan-guage restrictions on array usage (rules (A1\u2013A3) in Fig. 5)that enable complete symbolic checking of array accesses.RestrictionA3says that every index expression in an array\nreference must have a provably a\ufb03ne relationship to the al-\nlocated array size for that dimension. We also described an\ninterprocedural constraint propagation algorithm that prop-agates a\ufb03ne constraints on integer variables from callers tocallees (for incoming integer arguments and global scalars)and from callees to callers (for integer return values andglobal scalars), as described in [15]. We can then perform a\nsymbolic bounds check for each index expression using in-teger programming (our compiler uses the Omega Library\nfrom Maryland [14]).\nFor array safety, our primary goal in this work has been\nto evaluate the adequacy of these rules for a broad range ofembedded programs, and to relax the rules in limited waysthat can still be checked with existing compiler and integerprogramming technology. We have found (not surprisingly)\nthat embedded codes typically use arrays in much more com-\nplex ways than the control codes studied in our previouswork, as our experimental results in Section 5 show.\nOne practical issue for embedded programs is that they\nmake signi\ufb01cant use of I/O operations, the string library,and command line arguments. We added rule (A4)in Fig. 5\nto allow certain trusted string and I/O library routines.\nThe rule also speci\ufb01es that the arguments to trusted libraryroutines must satisfy some safety preconditions, to preventbu\ufb00er overruns within the library routines. Some libraryroutines also provide constraints relating the output of theroutine to its inputs which must be used by the compiler to\ncheck bu\ufb00er or string safety. For example, the expression n\n= read(fd, buf, count) where bufis a character array has\nthe safety precondition, (buf.size >= count) and a con-\nstraint on the return value, (n <= count) since readcan\nonly read up to countbytes. Some trusted library calls and\nthe corresponding constraints are listed in Table 1.\nLibrary Call\n Return Value\n Safety Pre-\nConstraints\n conditions\nn = read(fd, buf,\n n <= count\n buf.size\ncount)\n >= count\nn = puts(s)\n -\n -\np = memcpy(p1, p2,\n p.size = p1.size\n p1.size\nn)\n >= p2.size\nfp = fopen(p,m)\n -\n -\nn = getc(s)\n -\n -\nn = strlen(s)\n n < s.size\n -\np = strcpy(s1,s2)\n p.size = s1.size\n s1.size\n>= s2.size\np = strdup(s)\n p.size = s.size\n -\np = strncpy(s1, s2,\n p.size = s1.size\n s1.size > n\nn)\nTable 1: Some Trusted Library Routines with Im-pliedConstraintsand Preconditions\nThe advantage of providing trusted routines with pre-\nde\ufb01ned constraints (rather than including their source codein our analysis) is two-fold. It allows the body of the li-\nbrary routine to use non-a\ufb03ne array accesses or non-type-\n75 FreeSites(F,P) : set of call sites in F that may call poolfree on pool P directly or indirectly\nAllocSites(F,P): set of call sites in F that may call poolalloc on pool P directly or indirectlyPoolsFreed(F) : set of pool arguments of F that may have a poolfree in F or one of its calleesPoolsAlloced(F): set of pool arguments of F that may have a poolalloc in F or one of its callees\nAnalyzeFunction(Function F)\nbegin\nfor (each pool pointer SSA variable P in F) // formal argument or local variable\nfor (each call site FI in FreeSites(F, P))\nfor (each call AI in AllocSites(F, P1) where P1 != P)\nif (there exists a path from FI to AI in the Control Flow Graph)\nClassify (F,P) as \u2018\u2018Case 3\u2019\u2019\nfor (each call AI in AllocSites(F, P))\nif (there exists a path from FI to AI in the Control Flow Graph)\nClassify (F,P) as \u2018\u2018Case 2\u2019\u2019\nif !(Case 2 OR Case 3)\nClassify (F,P) as \u2018\u2018Case 1\u2019\u2019\nend;\nAnalyzeProgram(Program M)\nbegin\nfor (each SCC in CallGraph of M in post-order)\nwhile (change == true)\nchange = falsefor (each function F in the SCC)\nfor (each pool pointer variable P in F) // formal argument or local variable\nfor (each call site CS in F that has P as an argument)\nfor (each function CalledF that can be called at CS)\nif (CalledF is poolfree for P OR PoolsFreed(CalledF) contains P)\nif (FreeSites(F,P) does not contain CS)\nchange = trueadd CS to FreeSites(F,P)\nif (P is an argument of F)\nadd P to PoolsFreed(F)\nif (CalledF is poolalloc on P OR PoolsAlloced(CalledF) contains P)\nif (AllocSites(F, P) does not contain CS)\nchange = true\nadd CS to AllocSites(F,P)if (P is an argument of F)\nadd P to PoolsAlloced(F)\nfor (each function F in the SCC)\nAnalyzeFunction(F)\nend;\nFigure 4: Algorithmto identifyand classifypotential memoryreuse withinand betweenpools\nsafe code. Also, we do not need to compute or propagate\ndetailed constraints from the body of the library routine,thus speeding up the analysis.\nFinally, to ensure that string routines will not read beyond\nthe size of the array, we always initialize the last character\nin any array of characters to be null. We added rule (A5)to\nrequire that the program must not modify the last character,and enforce this rule by excluding the last element in thearray size expression used for safety checking.\nThe pre-conditions and return-value constraints are di-\nrectly incorporated into our existing analysis for arraybounds, described in [15]. We explain the basics of our ap-proach with the help of the example in Figure 6.\nTo prove the safety of any array access we \ufb01rst collect\nconstraints from the index expression and the array size ex-\npression by following SSA def-use edges, and collect branch\nconditions on which those de\ufb01nitions depend by using thecontrol dependence graph. In our example, for array ac-cess A[i], the constraints we generate are (A.size = 51-1)\nusing the def-use edges from the array declaration (notethat the last character is excluded from the size), (lenchar A[51]; // last character is set to null\n...k = read(fd, A, 50); // requires A.size >= 50\nif (k > 0) {\nlen = strlen(A); // implies len < A.sizefor (i=0; i < len; i++)\nif (A[i] == \u2019-\u2019)\nbreak;\n... // do other stuff with A, i\n}\nFigure 6: Array Usage Example\n< A.size && k <= 50) using the def-use edges and return\nvalue constraints on library functions strlen andread,a n d\n(i < len && k > 0) from the control dependence graph.\nInduction variable recognition allows us to generate usefulconstraints about loop index variables (e.g., i> =0 ), and\n(together with the renaming of variables in SSA form) al-lows us to disregard inconsistent equations like i=i+1\nfor both induction variables and ordinary variables. The\n76 Onallcontrol\ufb02owpaths,\n(A1) Theindexexpressionusedinanarrayaccessmustevaluatetoavaluewithintheboundsofthearray.\n(A2) Foralldynamicallyallocatedarrays,thesizeofthearraymustbeapositiveexpression.\n(A3) Ifanarray, A,isaccessedinsidealoop,then\n(a) theboundsoftheloopmustbeprovablya\ufb03netransformationsofthesizeof Aandouterloopindexvariablesorviceversa;\n(b) theindexexpressioninthearrayreference,mustbeaprovablya\ufb03netransformationofthevectorofloopindexvariables,or\nana\ufb03netransformationofthesizeof A;and\n(c) iftheindexexpressioninthearrayreferencedependsonasymbolicvariable swhichisindependentoftheloopindexvariable\n(i.e.,appearsintheconstantterminthea\ufb03nerepresentation),thenthememorylocationsaccessedbythatreferencehavetobeprovably independentofthevalueof s.\n(A4) Asetoftrustedlibraryroutineswithspeci\ufb01edpreconditionsmaybeused,andargumentspassedtothoseroutinesmustsatisfy\nthepreconditions.\n(A5) Thelastelementofacharacterarraycannotbemodi\ufb01edbytheprogram.\nFigure 5: SemanticRestrictions on Array Usage\ncomplete set of constraints that we generate for this ac-\ncess are (A.size = 50 && len < A.size && k <= 50 && i\n< len && k > 0 && i >= 0) . (Note that the interprocedu-\nral constraint propagation is not necessary in this simple\nexample but is essential for most realistic applications inpractice.) Finally, we add the illegal array bounds condi-tions for the reference ( (i < 0 || i >= A.size) in the ex-\nample), and then use the Omega library [14] to check if theresulting constraint system is satis\ufb01able. If not (as we have\nhere), the constraints have been proven inconsistent and the\narray access is safe.\nTo verify the precondition for the trusted library call read,\nwe simply need to check if the negation of the precondition(A.size >= 50) along with known constraints on buf.size\nand countresults in an inconsistent system. Here, (A.size\n< 50 && A.size = 50) trivially results in an inconsistent\nsystem. In this manner, we generate and check the precon-ditions for every trusted library call used by the program.\n5. RESULTS\nIn this section, we address some of the key questions about\nthe e\ufb00ectiveness of our semantic restrictions and compilertechniques used to check memory safety:\n1. How much e\ufb00ort is required to convert the existing\nembedded programs to conform to our semantic re-strictions ?\n2. Are the pool allocation transformation and heap safety\nanalysis powerful enough to enforce pointer and heapsafety statically in di\ufb00erent embedded programs?\n3. How often do we encounter pools from each of the three\ncategories in these programs?\n4. Are the array restrictions \ufb02exible enough to permit\nexisting embedded codes (without extensive changes)?\n5. Are the semantic restrictions and static analyses for\nstack safety su\ufb03cient for existing embedded codes?\n5.1 Methodology and Porting Effort\nOur test codes were derived from two embedded applica-\ntion benchmark suites: 13 from MiBench [12] and 4 fromMediaBench [19].\n7MiBench consists of embedded codes\n7Other codes in the benchmarks are not accepted by the\ncurrent LLVM C front-end, but will be evaluated using anew version of the front-end in the near future.from a variety of domains including telecommunications,\nsecurity, networking, etc. MediaBench are predominantlymultimedia codes. The program rastause a library called\nlibsphere whose source was not available. The experiments\nforrastaassumed that this library is safe and checked the\nsafety of the available source. The benchmarks, their sizes,and our results for each are shown in Table 2.\nWe found that a few lines of code had to be changed in\nseveral benchmarks to conform to our rules, particularly for\ntype safety and array safety. These are shown in the third\nand fourth columns of Table 2. The two largest changes werefor rule(T3)inrastaandg721.rastaused a union with a\n\ufb02oat and an array of four chars to swap the bytes of the \ufb02oatvalue. g721did the same for an unsigned int. We rewrote\nthe code using shift operations and eliminated the union.\nThe other changes for type safety were very small, e.g., ini-\ntializing local pointer variables before use within their par-ent function. For the array safety rules, we had to rewrite afew lines of code in 8 programs. The changes were generallyminimal and obvious. For instance, in blowfish a command\nline argument was accessed by iterating and checking if the\nlast character was null, which had to be rewritten to usestrlen() for the loop bound.\nBesides requiring very few modi\ufb01cations, the changes\nthemselves were simple and local and in most cases obvi-ous from reading the code or from compiler error messages.\nOverall, we believe the porting e\ufb00ort to use our compiler for\nstandard C programs is small to negligible.\n5.2 Effectiveness of Pointer and Heap Safety\nAnalysis\nTheHeap and Pointer Safety column in Table 2 shows\nthat our compiler was able to enforce safety of heap and\npointer usage for all 17 benchmarks we studied. About half\nthe benchmarks use no dynamic memory allocation (thoughthey still use pointers). For the other benchmarks, the samecolumn shows the di\ufb00erent categories of pools found in eachone. The results show that we were able to prove heap\nsafety without increase in memory consumption (i.e., Case\n1 or Case 2 pools \u2014 no reuse or only self-reuse), for all 13MiBench benchmarks and 2 of the 4 MediaBench codes.\nOnly two codes, rasta and epic, have pools with cross-\nreuse by other pools (Case 3), which can incur some increasein memory consumption. We believe this is an encouraging\nresult. Both rastaandepicmake extensive use of dynamic\n77 Benchmark\n Lines of\n Lines of Code\n Lines of Code\n Array Bounds\n Heap and\n Stack Safety\nCode\n Modi\ufb01ed\n Modi\ufb01ed\n Checker\n Pointer Safety\nfor type safety\n for array safety\n (Case)\nautomotive\nbasicmath\n 579\n 1\n 3\n Yes\n Yes\n Yes\nbitcount\n 17\n 5\n 0\n Yes\n Yes\n Yes\nqsort\n 156\n 0\n 1\n Yes\n Yes\n Yes\nsusan\n 2122\n 1\n 0\n No\n Yes (Case 1)\n Yes\no\ufb03ce\nstringsearch\n 3215\n 0\n 3\n Yes\n Yes\n Yes\nsecurity\nsha\n 269\n 0\n 1\n Yes\n Yes\n Yes\nblow\ufb01sh\n 1502\n 1\n 5\n Yes\n Yes\n Yes\nrijndael\n 1773\n 3\n 6\n Yes\n Yes\n No\nnetwork\ndijkstra\n 348\n 0\n 0\n No\n Yes (Case 2)\n Yes\ntelecomm\nCRC 32\n 282\n 0\n 1\n Yes\n Yes\n Yes\nadpcm codes\n 741\n 0\n 0\n No\n Yes\n Yes\nFFT\n 469\n 0\n 0\n No\n Yes (Case 1)\n Yes\ngsm\n 6038\n 0\n 0\n No\n Yes (Case 1)\n Yes\nmultimedia\ng721\n 1622\n 11\n 0\n No\n Yes\n Yes\nmpeg(decode)\n 9839\n 0\n 0\n No\n Yes (Case 1)\n Yes\nepic\n 3524\n 4\n 0\n No\n Yes (Cases 1,3)\n Yes\nrasta\n 7373\n 13\n 0\n No\n Yes (Cases 1,3)\n Yes\nTotals: 17\n 39869\n 39\n 20\n 8\n 17\n 16\nTable2: Benchmarks,code sizes,and experimentalresults\nmemory, yet they contain very few pools that fall under Case\n3: just 1 such pool out of a total of 13 pools in epicand 5\nout of 14 in rasta.I nf a c t ,3o ft h o s e5p o o l si n rastaalso\nhave self-reuse from the same pool, so that the e\ufb00ect of notfreeing memory to other pools is mitigated. We have alsoobserved that some case 3 pools (such as the one in epic)\ncould be converted to case 1 or 2 with more sophisticated\ncompiler analyses where the pooldestroy on a pool is moved\nas close to the last poolfree on the pool as possible without\ncompromising safety.\nAnother interesting use of dynamic memory is seen in\ndijkstra , where a linked list is alive throughout the pro-\ngram and repeatedly allocates and deallocates memory. In\na language with explicit regions such as Cyclone [11] or RT-\nJava, this list would have to go on a garbage collected heap.Finally, there were a number of Case 1 pools, which areamenable to the optimization of turning o\ufb00 individual objectfrees entirely, e\ufb00ectively performing static garbage collection\nwith no increase in memory usage.\nOverall, our results indicate that Case 3 occurs infre-\nquently even in complex embedded codes and typically neveroccurs at all in the simpler codes. This is strong empiricalevidence that our technique is powerful enough to enforceheap safety statically in a broad range of embedded codes.\n5.3 Effectiveness of Stack Safety Checks\nOur stack safety check ensures that pointers to the stack\nframe in a function are not accessible after that functionreturns. The last column of Table 2 shows that only 1 pro-gram ( rijndael ) failed this check. This occurred because\nData Structure Analysis is \ufb02ow-insensitive and can yeildfalse positives. In rijndael , a pointer to a local variable\nis stored in a global but the global is reinitialized by a calleeof the function before the function returns. Such cases must\nbe handled by restructuring the program. Overall, these re-\nsults indicate that stack safety should not be a signi\ufb01cantobstacle for static safety checking with our approach.\n5.4 Effectiveness of Array Access Checks\nOur array bounds checker passed 8 of the 13 benchmarks\nfrom MiBench and none from MediaBench, after the fewchanges described earlier. Interestingly, our tests detected 3\npotential array bound violations in the MiBench suite and\n2 in MediaBench: one each in dijkstra (both the large and\nsmall versions) and blowfish and two violations in g721.A l l\nof the errors except the ones in g721 were due to incorrectassumptions on number of command line arguments. Theerror in g721 was in using a \ufb01xed size bu\ufb00er to copy a \ufb01le\nname obtained from a command line argument. This could\ncause a stack corruption.\nThe array bounds checking algorithm failed to prove\nsafety for 9 of the codes. Two of these codes used non-a\ufb03nebit operations on the index variables. 5 other codes use indi-\nrect indexing for arrays, e.g., A[B[j]]. One possible solution\nwe aim to explore is to use Ada style subrange types forindex expressions, and attempt to prove their safety whenthe index values are computed .\nAnother two codes use memory locations in the heap to\nstore the size of an array, then load and use this size value\nin another function, requiring the compiler to prove that the\nheap location is not modi\ufb01ed in between. We believe thatthis can be handled fairly simply by interprocedural loadvalue numbering.\nOverall, safety checking of complex array references re-\nmains the most signi\ufb01cant obstacle to our goal of 100% static\nsafety checking for a broad class of embedded applications.\n78 5.5 Comparison with Control-C\nAll the control codes studied in our previous work on\nControl-C are accepted by our new compiler fully automati-\ncally, i.e., do not require the explicit use of single-region op-\nerations for dynamic memory management. Perhaps moreimportantly, the applications with Case 2 and Case 3 pools(Table 2) and many of those with Case 1 pools would bevery di\ufb03cult to implement with the single-region restrictionof Control-C. Moreover, since all the programs use command\nline arguments and most use other strings and I/O library\ncalls, none of them would accepted by the array boundschecks in Control-C. Thus, the new heap analysis and theimproved array access checks help to support a much largerclass of embedded codes than our previous work, and do so\nwithout program annotations.\n6. RELATED WORK\nThe broad approach of our work has been to identify\nminimal semantic restrictions on imperative programs andto develop new compiler techniques that together permitcomplete static checking of memory safety, without runtime\nchecks or garbage collection. To our knowledge no other\nprograming language or compiler system achieves this goalfor any non-trivial class of programs . We believe our re-\nsults show that we have achieved the goal for a signi\ufb01cantsubclass of embedded C programs, and the subclass is quite\nbroad if array bounds checks are ignored.\nSeveral alternative approaches have been taken to elim-\ninate speci\ufb01c types of runtime overheads, and we compareour approach with those below.\nThe Real-Time Speci\ufb01cation for Java (RT Java) [4] en-\nables programmers to avoid garbage collection entirely for\nsubsets of the heap by providing three additional types\nofMemoryArea s that are not garbage collected. Runtime\nchecks are required for ensuring safety of references betweenthe di\ufb00erent areas. Of these, the ScopedMemory type de-\n\ufb01nes nested (i.e., scoped) regions for dynamic allocation. Itis much more restrictive and has more runtime overheads\nthan our pools: memory can only be allocated from the\ncurrent region, it requires the programmer to specify regionentry/exit points, and perhaps most importantly, it requiresruntime checks to ensure that there are no references fromobjects in an outer scoped region (or from a di\ufb00erent typeof memory area) to an inner one [4]. Finally, RT Java also\ninherits the other runtime checking needs of standard Java\nsuch as for arrays, null pointer checks and type coercions.\nReal time garbage collection techniques (e.g., see [2] and\nthe references therein) use incremental collection methodsto reduce the unpredictability of garbage collection. Such\ntechniques can incur fairly high memory overhead to achieve\nacceptable real time behavior, up to 2.5 times the actualspace consumption of a program in recent work [2].\nAs an alternative to garbage collection, several recent lan-\nguages (e.g., RT Java [4], Cyclone [13, 11], and others [9, 5])have adopted mechanisms for region-based memory man-\nagement. These languages disallow direct deallocation of\nitems within a region in order to ensure program safety. Asdiscussed in the Introduction, these languages have two keydisadvantages relative to our work: (a) they generally re-quire extensive programmer annotations to identify regions;and (b) they provide no mechanisms to free or reuse memory\nwithin a region, so that data structures that shrink and grow(with non-nested object life times) must be put into a sepa-\nrate garbage-collected heap or may incur a potentially large\nincrease in memory consumption. (e.g., Cyclone and RTJava both include a separate garbage collected heap.) Au-tomatic region inference [25, 11] can eliminate or mitigatethe \ufb01rst but not the second, and has only been successfulfor type-safe languages without explicit deallocation.\nIn contrast to these approaches, we infer regions auto-\nmatically, we use no garbage collection, we permit explicitdeallocation of individual data items within regions, and weensure program safety through a combination of using ho-mogeneous regions and additional static analysis. There aretwo potential disadvantages in our work, however. We do\nnot prevent certain kinds of errors such as dangling pointer\nreferences (this is irrelevant for correct programs). Second,we rely heavily on interprocedural analysis (many of the an-notations in Cyclone and other languages are designed toavoid this need), but we retain the bene\ufb01ts of separate com-pilation by performing all our analysis at link-time (a key\nadvantage of using the LLVM compilation framework [16]).\nBoyapatiet al.[5] present a static type system combining\nownership types with region types, to eliminate the run-time checks needed for ensuring safe region deallocation inRT Java. As a region-based language, they have the samedi\ufb00erences from our work as discussed above. They pro-\nvide an additional mechanism based on \u201csub-regions\u201d of a\nregion for sharing region data safely across threads, usingreference counts to reclaim the data. We do not supportmulti-threaded applications so far.\nLinear types and alias types [6, 28, 7, 8] have been used\nto statically prove memory safety in the presence of explicit\ndeallocation of objects. They achieve this primarily with se-vere restrictions on aliases in a program, which so far havenot proved practical for realistic programs. One of theselanguages, Vault [7], also uses such a type system (muchmore successfully) to encode many important correctness\nrequirements for other dynamic resources within an appli-\ncation (e.g., \ufb01le handles and sockets). It would be very at-tractive to use Vault\u2019s mechanisms within our programmingenvironment to statically check key correctness requirementsof system calls and trusted libraries.\nA valuable strategy for compiler-based secure and reliable\nsystems is Proof-Carrying Code (PCC) [21]. The bene\ufb01t of\nPCC is that the safety checking compiler (usually a complex,unreliable system) can be untrusted, and only a simple proofchecker (which can be made much more reliable) is requiredwithin the trusted code base. Fundamentally, PCC does notchange what aspects of a program require static analysis and\nwhat require runtime checking \u2013 that still depends on the\nlanguage design and compiler capabilities. Thus, PCC isorthogonal to our work, and could be valuable for takingour safety-checking compiler outside the trusted code base.\nThere has been extensive work on static elimination of ar-\nray bounds checks (e.g., see [3, 27]), but the goal of that work\nis generally to eliminate a subset of bounds checks since com-plete elimination is impossible for standard languages. Incontrast, we impose carefully chosen language restrictions toenable compiler analysis to eliminate such checks entirely inconforming programs. Our previous work [15] discusses how\nthe interprocedural bounds checking algorithm presented\nthere compares with related work. Wagner et al.have de-\nveloped a tool for detection of bu\ufb00er overrun vulnerabili-ties in general C codes. Their analysis is necessarily impre-\n79 cise, however, both in terms of generating constraints (\ufb02ow-\ninsensitive) and solving them, resulting in many false pos-\nitives. In contrast, we use a more precise context-sensitiveanalysis and a more rigorous constraint solver.\n7. CONCLUSIONSAND FUTURE WORK\nIn this paper, we have described a set of semantic restric-\ntions and compiler techniques that together enable 100%static checking of memory safety for a signi\ufb01cant class oftype-safe embedded programs. The semantic restrictions\nare de\ufb01ned on a low-level language-independent type sys-\ntem and instruction set, and implemented in a language-independent, link-time compiler framework.\nThe key new result in this work is to show how an Auto-\nmatic Pool Allocation transformation allows us to ensure the\nsafety of dynamic memory management and pointer usage\nusing static checking alone (i.e., without garbage collectionor runtime checks on memory operations) and without any\nnew syntax. The compiler analysis helps to pinpoint the in-frequent case where certain data structures could experiencean increase in memory consumption. Our results show that\nthese techniques allow us to check heap and pointer safety\nfor all 17 embedded programs we studied. Our previoustechniques for eliminating null pointer checks and for stacksafety are also very e\ufb00ective for nearly all these programs,but our current analysis for checking array references can docomplete checking for only half the benchmarks we studied.\nOverall, we believe that codes certi\ufb01ed as safe by our com-\npiler can execute as fast as the those compiled by a native Ccompiler, while guaranteeing memory safety. Furthermore,we usually require minimal, simple, and completely portablerewriting of existing C programs to make them conform toour restrictions (often improving over the original!).\nThere are some key steps remaining before we can achieve\nour long term goal of a secure, low-overhead programmingenvironment based on the techniques above. First, we mustexplore better language and compiler support for complexarray operations. Second, we must provide a robust and\ufb02exible runtime environment with mechanisms to enforce\ncorrect usage of system calls and runtime libraries. Finally,\nwe must develop an architecture that tolerates bugs in thenecessarily complex compiler and runtime system.\n8. REFERENCES\n[1] T.M.Austin,S.E.Breach,andG.S.Sohi.E\ufb03cient\ndetectionofallpointerandarrayaccesserrors.In Proc.\nSIGPLAN \u201994 Conf. on Programming Language Design\nand Implementation ,Orlando,FL,June1994.\n[2] D.Bacon,P.Cheng,andV.Rajan.Areal-timegarbage\ncollectorwithlowoverheadandconsisitentutilization.In\nProc. 30th ACM Symp. Principles of Programming\nLanguages (POPL03) ,Jan.2003.\n[3] R.Bodik,R.Gupta,andV.Sarkar.ABCD:eliminating\narrayboundschecksondemand.In SIGPLAN Conf. on\nProg. Lang. Design and Implementation ,June2000.\n[4] G.BollellaandJ.Gosling.Thereal-timespeci\ufb01cationfor\nJava. Computer,33(6):47\u201354,2000.\n[5] C.Boyapati,A.Salcianu,W.Beebee,andM.Rinard.\nOwnershiptypesforsaferegion-basedmemory\nmanagementinreal-timejava.In SIGPLAN Conference on\nProgramming Language Design and Implementation ,2003.\n[6] K.Crary,D.Walker,andG.Morrisett.Typedmemory\nmanagementinacalculusofcapabilities.In Conference\nRecord of POPL 99: The 26th ACM SIGPLAN-SIGACTSymposium on Principles of Programming Languages, San\nAntonio, Texas ,pages262\u2013275,NewYork,NY,1999.[7] R.DeLineandM.Fahndrich.Enforcinghigh-levelprotocols\ninlow-levelsoftware.In Proc. SIGPLAN Conf. on\nProgramming Language Design and Implementation ,\nSnowbird,UT,June2001.\n[8] M.FahndrichandR.DeLine.Adoptionandfocus:\nPracticallineartypesforimperativeprogramming.In Proc.\nSIGPLAN Conference on Programming Language Design\nand Implementation ,June2002.\n[9] D.GayandA.Aiken.Memorymanagementwithexplicit\nregions.In SIGPLAN Conference on Programming\nLanguage Design and Implementation ,pages313\u2013323,\nMontreal,Canada,June1998.\n[10] J.Gosling,B.Joy,G.Steele,andG.Bracha. The Java\nLanguage Speci\ufb01cation .SunMicrosystems,2000.\n[11] D.Grossman,G.Morrisett,T.Jim,M.Hicks,Y.Wang,\nandJ.Cheney.Region-basedmemorymanagementin\ncyclone.In Proc. SIGPLAN Conf. on Programming\nLanguage Design and Implementation ,June2002.\n[12] M.R.Guthaus,J.S.Ringenberg,D.Ernst,T.M.Austin,\nT.Mudge,andR.B.Brown.Mibench: Afree,\ncommerciallyrepresentativeembeddedbenchmarksuite.In\nIEEE 4th Annual Workshop on Workload\nCharacterization ,Austin,TX,Dec.2001.\n[13] T.Jim,G.Morrisett,D.Grossman,M.Hicks,J.Cheney,\nandY.Wang.Cyclone: Asafedialectofc.In Proc.\nUSENIX Annual Technical Conference ,June2002.\n[14] W.Kelly,V.Maslov,W.Pugh,E.Rosser,T.Shpeisman,\nandD.Wonnacott.TheOmegaLibraryInterfaceGuide.\nTechnicalreport,ComputerScienceDept.,U.Maryland,\nCollegePark,Apr.1996.\n[15] S.Kowshik,D.Dhurjati,andV.Adve.Ensuringcode\nsafetywithoutruntimechecksforreal-timecontrolsystems.\nInProc. 2002 Conference on Compilers, Architecture and\nSynthesis for Embedded Systems ,Grenoble,Oct2002.\n[16] C.Lattner.LLVM:Aninfrastructureformulti-stage\noptimization.Master\u2019sthesis,ComputerScienceDept.,\nUniversityofIllinoisatUrbana-Champaign,Urbana,IL,\nDec2002. Seehttp://llvm.cs.uiuc.edu .\n[17] C.LattnerandV.Adve.AutomaticPoolAllocationfor\nDisjointDataStructures.In Proc. ACM SIGPLAN\nWorkshop on Memory System Performance ,Berlin,\nGermany,Jun2002.\n[18] C.LattnerandV.Adve.Datastructureanalysis: An\ne\ufb03cientcontext-sensitiveheapanalysis.Tech.Report\nUIUCDCS-R-2003-2340,ComputerScienceDept.,Univ.ofIllinoisatUrbana-Champaign,Apr2003.\n[19] C.Lee,M.Potkonjak,andW.H.Mangione-Smith.\nMediabench: Atoolforevaluatingandsynthesizing\nmultimediaandcommunicatonssystems.In International\nSymposium on Microarchitecture ,pages330\u2013335,1997.\n[20] P.LevisandD.Culler.Mate: Atinyvirtualmachinefor\nsensornetworks.In International Conference on\nArchitectural Support for Programming Languages andOperating Systems, San Jose, CA, USA ,Oct.2002.\n[21] G.C.Necula.Proof-carryingcode.In P r o c .o ft h e2 4 t h\nACM SIGPLAN-SIGACT Symposium on Principles ofProgramming Langauges (POPL \u201997) ,Paris,Jan.1997.\n[22] G.C.Necula,S.McPeak,andW.Weimer.Ccured:\nType-saferetro\ufb01ttingoflegacycode.In Proc. 29th ACM\nSymp. Principles of Programming Languages (POPL02) ,\nLondon,Jan.2002.\n[23] L.Sha.Dependablesystemupgrades.In Proceedings of\nIEEE Real Time System Symposium ,1998.\n[24] L.Sha.Usingsimplicitytocontrolcomplexity. IEEE\nSoftware,July/August2001.\n[25] M.TofteandL.Birkedal.Aregioninferencealgorithm.\nACM Trans. Prog. Lang. Sys. ,20(1),1998.\n[26] M.TofteandJ.-P.Talpin.Region-basedmemory\nmanagement. Information and Computation ,pages\n132(2):109\u2013176,Feb.1997.\n[27] D.Wagner,J.S.Foster,E.A.Brewer,andA.Aiken.A\n\ufb01rststeptowardsautomateddetectionofbu\ufb00eroverrun\nvulnerabilities.In Network and Distributed System Security\nSymposium,pages3\u201317,SanDiego,CA,February2000.\n[28] D.WalkerandG.Morrisett.Aliastypesforrecursivedata\nstructures. Lecture Notes in Comp. Sci. ,vol.2071,2001.\n80 ",
        "document_type": "research_paper",
        "owner": "Chris Lattnerr",
        "created_at": "2025-02-28T16:26:50.298067",
        "metadata": {
            "ai_analysis": {
                "originality_score": 0.85,
                "key_concepts": [
                    "memory safety",
                    "compilers",
                    "programming languages",
                    "static analysis",
                    "region management",
                    "automatic pool allocation"
                ],
                "potential_ip_aspects": [
                    "security",
                    "protection"
                ]
            }
        },
        "hash": "92f0cf713ad0f6242401275fed984a5de6118a6487aef08716d13ef0ceec09f4"
    }
}